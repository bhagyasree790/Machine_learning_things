{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIx3137FpWs5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/k-medoids_clustered_dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "_x6n20qPptA6",
        "outputId": "a9788bdb-d32e-43b6-968d-abc1cd46d870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Access to electricity (% of population)  \\\n",
              "0  2000                                 4.446891   \n",
              "1  2001                                 9.294527   \n",
              "2  2002                                14.133616   \n",
              "3  2003                                18.971165   \n",
              "4  2004                                23.814182   \n",
              "\n",
              "   Agricultural land (% of land area)  \\\n",
              "0                           57.945817   \n",
              "1                           57.947350   \n",
              "2                           57.939684   \n",
              "3                           58.083805   \n",
              "4                           58.151266   \n",
              "\n",
              "   Annual freshwater withdrawals, total (% of internal resources)  \\\n",
              "0                                          43.015907                \n",
              "1                                          43.015907                \n",
              "2                                          43.015907                \n",
              "3                                          43.015907                \n",
              "4                                          43.015907                \n",
              "\n",
              "   Arable land (% of land area)  Forest area (% of land area)  \\\n",
              "0                     11.779587                      1.852782   \n",
              "1                     11.779587                      1.852782   \n",
              "2                     11.771921                      1.852782   \n",
              "3                     11.916042                      1.852782   \n",
              "4                     11.983503                      1.852782   \n",
              "\n",
              "   Electric power consumption (kWh per capita)  \\\n",
              "0                                  1586.591120   \n",
              "1                                  1587.375364   \n",
              "2                                  1649.718098   \n",
              "3                                  1738.666619   \n",
              "4                                  1841.168267   \n",
              "\n",
              "   Energy use (kg of oil equivalent per capita)  \\\n",
              "0                                    985.730004   \n",
              "1                                   1011.679617   \n",
              "2                                   1034.410867   \n",
              "3                                   1010.524231   \n",
              "4                                   1121.869767   \n",
              "\n",
              "   Renewable electricity output (% of total electricity output)  \\\n",
              "0                                          74.989094              \n",
              "1                                          72.811460              \n",
              "2                                          79.063971              \n",
              "3                                          70.249729              \n",
              "4                                          70.890841              \n",
              "\n",
              "   Renewable energy consumption (% of total final energy consumption)  \\\n",
              "0                                              44.99                    \n",
              "1                                              45.60                    \n",
              "2                                              37.83                    \n",
              "3                                              36.66                    \n",
              "4                                              44.24                    \n",
              "\n",
              "   Population growth (annual %)  GDP per capita (current US$)  \\\n",
              "0                      1.443803                    182.174037   \n",
              "1                      0.742517                    182.174037   \n",
              "2                      6.449321                    182.174037   \n",
              "3                      7.541019                    199.643228   \n",
              "4                      3.933178                    221.830531   \n",
              "\n",
              "   CO2 emissions (metric tons per capita)  Cluster  \n",
              "0                                0.055167        0  \n",
              "1                                0.055293        0  \n",
              "2                                0.066810        0  \n",
              "3                                0.073005        0  \n",
              "4                                0.054867        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbd08d44-a746-4fff-ba84-d66aa8807bd5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Access to electricity (% of population)</th>\n",
              "      <th>Agricultural land (% of land area)</th>\n",
              "      <th>Annual freshwater withdrawals, total (% of internal resources)</th>\n",
              "      <th>Arable land (% of land area)</th>\n",
              "      <th>Forest area (% of land area)</th>\n",
              "      <th>Electric power consumption (kWh per capita)</th>\n",
              "      <th>Energy use (kg of oil equivalent per capita)</th>\n",
              "      <th>Renewable electricity output (% of total electricity output)</th>\n",
              "      <th>Renewable energy consumption (% of total final energy consumption)</th>\n",
              "      <th>Population growth (annual %)</th>\n",
              "      <th>GDP per capita (current US$)</th>\n",
              "      <th>CO2 emissions (metric tons per capita)</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>4.446891</td>\n",
              "      <td>57.945817</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1586.591120</td>\n",
              "      <td>985.730004</td>\n",
              "      <td>74.989094</td>\n",
              "      <td>44.99</td>\n",
              "      <td>1.443803</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055167</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>9.294527</td>\n",
              "      <td>57.947350</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1587.375364</td>\n",
              "      <td>1011.679617</td>\n",
              "      <td>72.811460</td>\n",
              "      <td>45.60</td>\n",
              "      <td>0.742517</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055293</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>14.133616</td>\n",
              "      <td>57.939684</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.771921</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1649.718098</td>\n",
              "      <td>1034.410867</td>\n",
              "      <td>79.063971</td>\n",
              "      <td>37.83</td>\n",
              "      <td>6.449321</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.066810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>18.971165</td>\n",
              "      <td>58.083805</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.916042</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1738.666619</td>\n",
              "      <td>1010.524231</td>\n",
              "      <td>70.249729</td>\n",
              "      <td>36.66</td>\n",
              "      <td>7.541019</td>\n",
              "      <td>199.643228</td>\n",
              "      <td>0.073005</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>23.814182</td>\n",
              "      <td>58.151266</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.983503</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1841.168267</td>\n",
              "      <td>1121.869767</td>\n",
              "      <td>70.890841</td>\n",
              "      <td>44.24</td>\n",
              "      <td>3.933178</td>\n",
              "      <td>221.830531</td>\n",
              "      <td>0.054867</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbd08d44-a746-4fff-ba84-d66aa8807bd5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbd08d44-a746-4fff-ba84-d66aa8807bd5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbd08d44-a746-4fff-ba84-d66aa8807bd5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd4c97a3-c67b-4704-89bc-d2c4b78922b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd4c97a3-c67b-4704-89bc-d2c4b78922b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd4c97a3-c67b-4704-89bc-d2c4b78922b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5586,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2000,\n        \"max\": 2020,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2000,\n          2017,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Access to electricity (% of population)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.009307167116457,\n        \"min\": 0.796382964,\n        \"max\": 100.0,\n        \"num_unique_values\": 3517,\n        \"samples\": [\n          18.72191048,\n          99.64420319,\n          57.97229767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agricultural land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.08418270854103,\n        \"min\": 0.448717949,\n        \"max\": 85.48737287,\n        \"num_unique_values\": 4205,\n        \"samples\": [\n          38.38383838,\n          60.42062566,\n          39.54077135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Annual freshwater withdrawals, total (% of internal resources)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 550.832181089681,\n        \"min\": 0.02036036,\n        \"max\": 7750.0,\n        \"num_unique_values\": 2609,\n        \"samples\": [\n          0.985916515,\n          318.3845455,\n          5832.045455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Arable land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.513691681893778,\n        \"min\": 0.043140638,\n        \"max\": 64.14688484,\n        \"num_unique_values\": 3804,\n        \"samples\": [\n          7.869067642,\n          44.19781931,\n          28.97936625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forest area (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.913181689877433,\n        \"min\": 0.0,\n        \"max\": 98.33891026,\n        \"num_unique_values\": 4408,\n        \"samples\": [\n          33.70594801,\n          90.03712486,\n          25.05576326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Electric power consumption (kWh per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4325.196010328713,\n        \"min\": 22.48184434,\n        \"max\": 54799.17471,\n        \"num_unique_values\": 3644,\n        \"samples\": [\n          2658.418628118782,\n          206.2771632,\n          8174.408162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Energy use (kg of oil equivalent per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4760.337500642505,\n        \"min\": 9.579196003,\n        \"max\": 197209.00845990723,\n        \"num_unique_values\": 3807,\n        \"samples\": [\n          695.1348324,\n          565.3273918,\n          3205.328271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable electricity output (% of total electricity output)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.55740141599933,\n        \"min\": -2.76281104889535,\n        \"max\": 100.47239374276964,\n        \"num_unique_values\": 4436,\n        \"samples\": [\n          21.57118997,\n          99.89101477,\n          24.69010449387077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable energy consumption (% of total final energy consumption)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.609065972127446,\n        \"min\": 0.0,\n        \"max\": 98.34,\n        \"num_unique_values\": 3997,\n        \"samples\": [\n          79.02,\n          21.19,\n          77.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population growth (annual %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4711193274065608,\n        \"min\": -6.852117676,\n        \"max\": 19.36042866,\n        \"num_unique_values\": 5523,\n        \"samples\": [\n          0.025087267,\n          -1.666382643,\n          0.76783354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP per capita (current US$)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22028.338711031764,\n        \"min\": 110.4608747,\n        \"max\": 204097.114,\n        \"num_unique_values\": 5351,\n        \"samples\": [\n          1492.377075,\n          4359.7924,\n          15595.6365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2 emissions (metric tons per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.890510317312629,\n        \"min\": 0.0,\n        \"max\": 47.65696201,\n        \"num_unique_values\": 4359,\n        \"samples\": [\n          8.860393054,\n          0.215113481,\n          0.332610017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8mYxkmEpzvB",
        "outputId": "a7158382-24d3-46c7-e572-de02110bf0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              "0    4391\n",
              "1    1195\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9igvvm0_p_1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Cluster'], axis=1)\n",
        "y = df['Cluster']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7okKXQ8qDee",
        "outputId": "abf2ef11-ef59-49d7-dd15-5ee5fe479370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4468, 13)\n",
            "X_test shape: (1118, 13)\n",
            "y_train shape: (4468,)\n",
            "y_test shape: (1118,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "IbQS5keKqKR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "vokiJxcgqHKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1LwXfHTqTTt",
        "outputId": "6380a45e-1d6b-438d-c6b8-70d393702aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9915966386554622\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9988649262202043\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9915966386554622\n",
            "Precision: 1.0\n",
            "Recall: 0.9915966386554622\n",
            "F1 Score: 0.9957805907172996\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Overall accuracy: 0.998211091234347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"\\nFold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN7wBJ53qhB0",
        "outputId": "d4f99ebd-8e04-4850-e059-88b14c440de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9915966386554622\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9988649262202043\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9915966386554622\n",
            "Precision: 1.0\n",
            "Recall: 0.9915966386554622\n",
            "F1 Score: 0.9957805907172996\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977142857142857\n",
            "Precision: 1.0\n",
            "Recall: 0.9977142857142857\n",
            "F1 Score: 0.9988558352402745\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9977142857142857\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9918032786885246\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9958847736625513\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9957983193277311\n",
            "Sensitivity: 0.9977246871444824\n",
            "Precision: 0.9988610478359908\n",
            "Recall: 0.9977246871444824\n",
            "F1 Score: 0.9982925441092771\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9977246871444824\n",
            "Sensitivity: 0.9957983193277311\n",
            "Precision: 0.9916317991631799\n",
            "Recall: 0.9957983193277311\n",
            "F1 Score: 0.9937106918238993\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.996\n",
            "Sensitivity: 0.9988465974625144\n",
            "Precision: 0.9988465974625144\n",
            "Recall: 0.9988465974625144\n",
            "F1 Score: 0.9988465974625144\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9988465974625144\n",
            "Sensitivity: 0.996\n",
            "Precision: 0.996\n",
            "Recall: 0.996\n",
            "F1 Score: 0.996\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9943820224719101\n",
            "Precision: 1.0\n",
            "Recall: 0.9943820224719101\n",
            "F1 Score: 0.9971830985915493\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9943820224719101\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.978448275862069\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9891067538126361\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9966789915966388\n",
            "Sensitivity: 0.9977335185586386\n",
            "Precision: 0.999088014320472\n",
            "Recall: 0.9977335185586386\n",
            "F1 Score: 0.998408600324764\n",
            "Accuracy: 0.9974936058923485\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9977335185586386\n",
            "Sensitivity: 0.9966789915966388\n",
            "Precision: 0.9915766707427547\n",
            "Recall: 0.9966789915966388\n",
            "F1 Score: 0.9940965620032772\n",
            "Accuracy: 0.9974936058923485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DT"
      ],
      "metadata": {
        "id": "YIEWdOCLquiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEGwJDqpqos8",
        "outputId": "0e8ccbdb-6aaf-4461-8e6a-168ab67ec422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9955056179775281\n",
            "Precision: 1.0\n",
            "Recall: 0.9955056179775281\n",
            "F1 Score: 0.9977477477477478\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9955056179775281\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9826839826839827\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9912663755458515\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Overall accuracy: 0.9964189794091316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = dt.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTndDYgGqxuC",
        "outputId": "7440dcff-ef71-4b64-bae9-8cf4d4ae4bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9873949579831933\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9966024915062288\n",
            "Recall: 1.0\n",
            "F1 Score: 0.998298355076574\n",
            "Accuracy: 0.9973166368515206\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9873949579831933\n",
            "Precision: 1.0\n",
            "Recall: 0.9873949579831933\n",
            "F1 Score: 0.9936575052854123\n",
            "Accuracy: 0.9973166368515206\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9988571428571429\n",
            "Precision: 1.0\n",
            "Recall: 0.9988571428571429\n",
            "F1 Score: 0.9994282447112636\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9988571428571429\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9958847736625515\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9979381443298969\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.98\n",
            "Sensitivity: 0.9988465974625144\n",
            "Precision: 0.9942594718714122\n",
            "Recall: 0.9988465974625144\n",
            "F1 Score: 0.9965477560414269\n",
            "Accuracy: 0.9946284691136974\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9988465974625144\n",
            "Sensitivity: 0.98\n",
            "Precision: 0.9959349593495935\n",
            "Recall: 0.98\n",
            "F1 Score: 0.9879032258064516\n",
            "Accuracy: 0.9946284691136974\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9955056179775281\n",
            "Precision: 1.0\n",
            "Recall: 0.9955056179775281\n",
            "F1 Score: 0.9977477477477478\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9955056179775281\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9826839826839827\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9912663755458515\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9934789915966388\n",
            "Sensitivity: 0.9986418716594372\n",
            "Precision: 0.9981723926755283\n",
            "Recall: 0.9986418716594372\n",
            "F1 Score: 0.9984044207154025\n",
            "Accuracy: 0.9974937660453265\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9986418716594372\n",
            "Sensitivity: 0.9934789915966388\n",
            "Precision: 0.9949007431392255\n",
            "Recall: 0.9934789915966388\n",
            "F1 Score: 0.9941530501935224\n",
            "Accuracy: 0.9974937660453265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network"
      ],
      "metadata": {
        "id": "oAVQ5g4Iq3jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUjZWlhgq3GA",
        "outputId": "e608c406-3b79-4b19-c1a2-f48895a5eb98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.973568281938326\n",
            "Sensitivity: 0.998876404494382\n",
            "Precision: 0.9932960893854749\n",
            "Recall: 0.998876404494382\n",
            "F1 Score: 0.996078431372549\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.998876404494382\n",
            "Sensitivity: 0.973568281938326\n",
            "Precision: 0.9954954954954955\n",
            "Recall: 0.973568281938326\n",
            "F1 Score: 0.9844097995545658\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Overall accuracy: 0.9937332139659804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sulgfk4rF6u",
        "outputId": "a3ddaa3f-44b3-4cf2-f118-d1e44d441924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9873949579831933\n",
            "Sensitivity: 0.9943181818181818\n",
            "Precision: 0.9965831435079726\n",
            "Recall: 0.9943181818181818\n",
            "F1 Score: 0.9954493742889646\n",
            "Accuracy: 0.9928443649373881\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9943181818181818\n",
            "Sensitivity: 0.9873949579831933\n",
            "Precision: 0.9791666666666666\n",
            "Recall: 0.9873949579831933\n",
            "F1 Score: 0.9832635983263599\n",
            "Accuracy: 0.9928443649373881\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9954285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9954285714285714\n",
            "F1 Score: 0.9977090492554409\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9954285714285714\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.983739837398374\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9918032786885246\n",
            "Accuracy: 0.9964189794091316\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8949579831932774\n",
            "Sensitivity: 0.9988623435722411\n",
            "Precision: 0.9723145071982281\n",
            "Recall: 0.9988623435722411\n",
            "F1 Score: 0.9854096520763187\n",
            "Accuracy: 0.9767233661593554\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9988623435722411\n",
            "Sensitivity: 0.8949579831932774\n",
            "Precision: 0.9953271028037384\n",
            "Recall: 0.8949579831932774\n",
            "F1 Score: 0.9424778761061947\n",
            "Accuracy: 0.9767233661593554\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.98\n",
            "Sensitivity: 0.9988465974625144\n",
            "Precision: 0.9942594718714122\n",
            "Recall: 0.9988465974625144\n",
            "F1 Score: 0.9965477560414269\n",
            "Accuracy: 0.9946284691136974\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9988465974625144\n",
            "Sensitivity: 0.98\n",
            "Precision: 0.9959349593495935\n",
            "Recall: 0.98\n",
            "F1 Score: 0.9879032258064516\n",
            "Accuracy: 0.9946284691136974\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.973568281938326\n",
            "Sensitivity: 0.998876404494382\n",
            "Precision: 0.9932960893854749\n",
            "Recall: 0.998876404494382\n",
            "F1 Score: 0.996078431372549\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.998876404494382\n",
            "Sensitivity: 0.973568281938326\n",
            "Precision: 0.9954954954954955\n",
            "Recall: 0.973568281938326\n",
            "F1 Score: 0.9844097995545658\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9671842446229594\n",
            "Sensitivity: 0.9972664197551782\n",
            "Precision: 0.9912906423926175\n",
            "Recall: 0.9972664197551782\n",
            "F1 Score: 0.9942388526069401\n",
            "Accuracy: 0.9908696787171106\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9972664197551782\n",
            "Sensitivity: 0.9671842446229594\n",
            "Precision: 0.9899328123427736\n",
            "Recall: 0.9671842446229594\n",
            "F1 Score: 0.9779715556964194\n",
            "Accuracy: 0.9908696787171106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "h1yH7lNdrNoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "drLUHVDerM6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier (GaussianNB for continuous features)\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the entire training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=nb.classes_)\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(nb.classes_):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZyr_DRErUcz",
        "outputId": "868f94c7-b4e8-4360-d41e-f8c4203aaa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9911894273127754\n",
            "Sensitivity: 0.8629213483146068\n",
            "Precision: 0.9974025974025974\n",
            "Recall: 0.8629213483146068\n",
            "F1 Score: 0.925301204819277\n",
            "Accuracy: 0.8889883616830797\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.8629213483146068\n",
            "Sensitivity: 0.9911894273127754\n",
            "Precision: 0.6484149855907781\n",
            "Recall: 0.9911894273127754\n",
            "F1 Score: 0.7839721254355402\n",
            "Accuracy: 0.8889883616830797\n",
            "\n",
            "Overall accuracy: 0.8889883616830797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nb.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nb.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwnpUpvqrbg3",
        "outputId": "aab9e975-a789-4d31-eda0-913a835a0bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8579545454545454\n",
            "Precision: 1.0\n",
            "Recall: 0.8579545454545454\n",
            "F1 Score: 0.9235474006116208\n",
            "Accuracy: 0.8881932021466905\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.8579545454545454\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.6556473829201102\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7920133111480865\n",
            "Accuracy: 0.8881932021466905\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8594285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.8594285714285714\n",
            "F1 Score: 0.9244007375537799\n",
            "Accuracy: 0.8898836168307968\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.8594285714285714\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.663013698630137\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7973640856672158\n",
            "Accuracy: 0.8898836168307968\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.856655290102389\n",
            "Precision: 1.0\n",
            "Recall: 0.856655290102389\n",
            "F1 Score: 0.9227941176470588\n",
            "Accuracy: 0.8871978513876455\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.856655290102389\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.6538461538461539\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7906976744186047\n",
            "Accuracy: 0.8871978513876455\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.996\n",
            "Sensitivity: 0.8754325259515571\n",
            "Precision: 0.9986842105263158\n",
            "Recall: 0.8754325259515571\n",
            "F1 Score: 0.9330055316533498\n",
            "Accuracy: 0.9024171888988362\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.8754325259515571\n",
            "Sensitivity: 0.996\n",
            "Precision: 0.6974789915966386\n",
            "Recall: 0.996\n",
            "F1 Score: 0.8204283360790774\n",
            "Accuracy: 0.9024171888988362\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9911894273127754\n",
            "Sensitivity: 0.8629213483146068\n",
            "Precision: 0.9974025974025974\n",
            "Recall: 0.8629213483146068\n",
            "F1 Score: 0.925301204819277\n",
            "Accuracy: 0.8889883616830797\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.8629213483146068\n",
            "Sensitivity: 0.9911894273127754\n",
            "Precision: 0.6484149855907781\n",
            "Recall: 0.9911894273127754\n",
            "F1 Score: 0.7839721254355402\n",
            "Accuracy: 0.8889883616830797\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9974378854625551\n",
            "Sensitivity: 0.862478456250334\n",
            "Precision: 0.9992173615857827\n",
            "Recall: 0.862478456250334\n",
            "F1 Score: 0.9258097984570173\n",
            "Accuracy: 0.8913360441894096\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.862478456250334\n",
            "Sensitivity: 0.9974378854625551\n",
            "Precision: 0.6636802425167635\n",
            "Recall: 0.9974378854625551\n",
            "F1 Score: 0.796895106549705\n",
            "Accuracy: 0.8913360441894096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Linear"
      ],
      "metadata": {
        "id": "cNzIcelPrjoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "_pJoYiHZrhpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM linear classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "labels = y.unique()\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Print evaluation metrics\n",
        "# Iterate over indices and labels simultaneously\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5NvuNKKrp6T",
        "outputId": "26143670-82cf-4343-8b1e-539c5d030a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977528089887641\n",
            "Precision: 1.0\n",
            "Recall: 0.9977528089887641\n",
            "F1 Score: 0.998875140607424\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9977528089887641\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9912663755458515\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9956140350877193\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Overall accuracy: 0.9982094897045658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a linear kernel\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlvLHCvZrs9G",
        "outputId": "873213c5-4861-4800-80b7-64bc20fc5035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977528089887641\n",
            "Precision: 1.0\n",
            "Recall: 0.9977528089887641\n",
            "F1 Score: 0.998875140607424\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9977528089887641\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9912663755458515\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9956140350877193\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9995505617977528\n",
            "Precision: 1.0\n",
            "Recall: 0.9995505617977528\n",
            "F1 Score: 0.9997750281214849\n",
            "Accuracy: 0.9996418979409132\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9995505617977528\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9982532751091704\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9991228070175439\n",
            "Accuracy: 0.9996418979409132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Non-linear"
      ],
      "metadata": {
        "id": "h7XHZtO05tfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (e.g., 'rbf')\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# Fit the classifier on the entire dataset\n",
        "svm.fit(X, y)\n",
        "\n",
        "# Predict on the same dataset\n",
        "y_pred = svm.predict(X)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "print(\"Evaluation Metrics for SVM Non-Linear Classification:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjxVGxF5xmb",
        "outputId": "7e4f1685-20ba-4b7c-881d-5064db0cfbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for SVM Non-Linear Classification:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9997722614438624\n",
            "Sensitivity: 0.9933054393305439\n",
            "Precision: 0.9991582491582491\n",
            "Recall: 0.9933054393305439\n",
            "F1 Score: 0.9962232480067142\n",
            "Accuracy: 0.9983888292158969\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9997722614438624\n",
            "Sensitivity: 0.9933054393305439\n",
            "Precision: 0.9991582491582491\n",
            "Recall: 0.9933054393305439\n",
            "F1 Score: 0.9962232480067142\n",
            "Accuracy: 0.9983888292158969\n",
            "\n",
            "Overall accuracy: 0.9983888292158969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (RBF)\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1oDuZVC7Cks",
        "outputId": "86d29484-1c33-42bf-d72b-045c5a72694e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9915966386554622\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9988649262202043\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9915966386554622\n",
            "Precision: 1.0\n",
            "Recall: 0.9915966386554622\n",
            "F1 Score: 0.9957805907172996\n",
            "Accuracy: 0.998211091234347\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9957983193277311\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9988636363636364\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9994314951677089\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9957983193277311\n",
            "Precision: 1.0\n",
            "Recall: 0.9957983193277311\n",
            "F1 Score: 0.9978947368421053\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.984\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9954075774971297\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9976985040276178\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.984\n",
            "Precision: 1.0\n",
            "Recall: 0.984\n",
            "F1 Score: 0.9919354838709677\n",
            "Accuracy: 0.9964189794091316\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977528089887641\n",
            "Precision: 1.0\n",
            "Recall: 0.9977528089887641\n",
            "F1 Score: 0.998875140607424\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9977528089887641\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9912663755458515\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9956140350877193\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9942789915966387\n",
            "Sensitivity: 0.9995505617977528\n",
            "Precision: 0.9984007280329242\n",
            "Recall: 0.9995505617977528\n",
            "F1 Score: 0.9989740132045911\n",
            "Accuracy: 0.9983888610400655\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9995505617977528\n",
            "Sensitivity: 0.9942789915966387\n",
            "Precision: 0.9982532751091704\n",
            "Recall: 0.9942789915966387\n",
            "F1 Score: 0.9962449693036184\n",
            "Accuracy: 0.9983888610400655\n"
          ]
        }
      ]
    }
  ]
}