{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoZc_bqx7s7o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Hierarchy_clustered_df2.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "1K-BC9yg-Np0",
        "outputId": "ef752377-1762-4613-ecff-1aef95f01587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Access to electricity (% of population)  \\\n",
              "0  2000                                 4.446891   \n",
              "1  2001                                 9.294527   \n",
              "2  2002                                14.133616   \n",
              "3  2003                                18.971165   \n",
              "4  2004                                23.814182   \n",
              "\n",
              "   Agricultural land (% of land area)  \\\n",
              "0                           57.945817   \n",
              "1                           57.947350   \n",
              "2                           57.939684   \n",
              "3                           58.083805   \n",
              "4                           58.151266   \n",
              "\n",
              "   Annual freshwater withdrawals, total (% of internal resources)  \\\n",
              "0                                          43.015907                \n",
              "1                                          43.015907                \n",
              "2                                          43.015907                \n",
              "3                                          43.015907                \n",
              "4                                          43.015907                \n",
              "\n",
              "   Arable land (% of land area)  Forest area (% of land area)  \\\n",
              "0                     11.779587                      1.852782   \n",
              "1                     11.779587                      1.852782   \n",
              "2                     11.771921                      1.852782   \n",
              "3                     11.916042                      1.852782   \n",
              "4                     11.983503                      1.852782   \n",
              "\n",
              "   Electric power consumption (kWh per capita)  \\\n",
              "0                                  1586.591120   \n",
              "1                                  1587.375364   \n",
              "2                                  1649.718098   \n",
              "3                                  1738.666619   \n",
              "4                                  1841.168267   \n",
              "\n",
              "   Energy use (kg of oil equivalent per capita)  \\\n",
              "0                                    985.730004   \n",
              "1                                   1011.679617   \n",
              "2                                   1034.410867   \n",
              "3                                   1010.524231   \n",
              "4                                   1121.869767   \n",
              "\n",
              "   Renewable electricity output (% of total electricity output)  \\\n",
              "0                                          74.989094              \n",
              "1                                          72.811460              \n",
              "2                                          79.063971              \n",
              "3                                          70.249729              \n",
              "4                                          70.890841              \n",
              "\n",
              "   Renewable energy consumption (% of total final energy consumption)  \\\n",
              "0                                              44.99                    \n",
              "1                                              45.60                    \n",
              "2                                              37.83                    \n",
              "3                                              36.66                    \n",
              "4                                              44.24                    \n",
              "\n",
              "   Population growth (annual %)  GDP per capita (current US$)  \\\n",
              "0                      1.443803                    182.174037   \n",
              "1                      0.742517                    182.174037   \n",
              "2                      6.449321                    182.174037   \n",
              "3                      7.541019                    199.643228   \n",
              "4                      3.933178                    221.830531   \n",
              "\n",
              "   CO2 emissions (metric tons per capita)  Cluster  \n",
              "0                                0.055167        1  \n",
              "1                                0.055293        1  \n",
              "2                                0.066810        1  \n",
              "3                                0.073005        1  \n",
              "4                                0.054867        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fae741c-64e8-4db0-a25f-76d08a1eec7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Access to electricity (% of population)</th>\n",
              "      <th>Agricultural land (% of land area)</th>\n",
              "      <th>Annual freshwater withdrawals, total (% of internal resources)</th>\n",
              "      <th>Arable land (% of land area)</th>\n",
              "      <th>Forest area (% of land area)</th>\n",
              "      <th>Electric power consumption (kWh per capita)</th>\n",
              "      <th>Energy use (kg of oil equivalent per capita)</th>\n",
              "      <th>Renewable electricity output (% of total electricity output)</th>\n",
              "      <th>Renewable energy consumption (% of total final energy consumption)</th>\n",
              "      <th>Population growth (annual %)</th>\n",
              "      <th>GDP per capita (current US$)</th>\n",
              "      <th>CO2 emissions (metric tons per capita)</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>4.446891</td>\n",
              "      <td>57.945817</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1586.591120</td>\n",
              "      <td>985.730004</td>\n",
              "      <td>74.989094</td>\n",
              "      <td>44.99</td>\n",
              "      <td>1.443803</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>9.294527</td>\n",
              "      <td>57.947350</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1587.375364</td>\n",
              "      <td>1011.679617</td>\n",
              "      <td>72.811460</td>\n",
              "      <td>45.60</td>\n",
              "      <td>0.742517</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055293</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>14.133616</td>\n",
              "      <td>57.939684</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.771921</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1649.718098</td>\n",
              "      <td>1034.410867</td>\n",
              "      <td>79.063971</td>\n",
              "      <td>37.83</td>\n",
              "      <td>6.449321</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.066810</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>18.971165</td>\n",
              "      <td>58.083805</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.916042</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1738.666619</td>\n",
              "      <td>1010.524231</td>\n",
              "      <td>70.249729</td>\n",
              "      <td>36.66</td>\n",
              "      <td>7.541019</td>\n",
              "      <td>199.643228</td>\n",
              "      <td>0.073005</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>23.814182</td>\n",
              "      <td>58.151266</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.983503</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1841.168267</td>\n",
              "      <td>1121.869767</td>\n",
              "      <td>70.890841</td>\n",
              "      <td>44.24</td>\n",
              "      <td>3.933178</td>\n",
              "      <td>221.830531</td>\n",
              "      <td>0.054867</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fae741c-64e8-4db0-a25f-76d08a1eec7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fae741c-64e8-4db0-a25f-76d08a1eec7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fae741c-64e8-4db0-a25f-76d08a1eec7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfbc1e84-fca5-4353-9401-53ebddea4915\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfbc1e84-fca5-4353-9401-53ebddea4915')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfbc1e84-fca5-4353-9401-53ebddea4915 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5586,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2000,\n        \"max\": 2020,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2000,\n          2017,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Access to electricity (% of population)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.009307167116457,\n        \"min\": 0.796382964,\n        \"max\": 100.0,\n        \"num_unique_values\": 3517,\n        \"samples\": [\n          18.72191048,\n          99.64420319,\n          57.97229767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agricultural land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.08418270854103,\n        \"min\": 0.448717949,\n        \"max\": 85.48737287,\n        \"num_unique_values\": 4205,\n        \"samples\": [\n          38.38383838,\n          60.42062566,\n          39.54077135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Annual freshwater withdrawals, total (% of internal resources)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 550.832181089681,\n        \"min\": 0.02036036,\n        \"max\": 7750.0,\n        \"num_unique_values\": 2609,\n        \"samples\": [\n          0.985916515,\n          318.3845455,\n          5832.045455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Arable land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.513691681893778,\n        \"min\": 0.043140638,\n        \"max\": 64.14688484,\n        \"num_unique_values\": 3804,\n        \"samples\": [\n          7.869067642,\n          44.19781931,\n          28.97936625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forest area (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.913181689877433,\n        \"min\": 0.0,\n        \"max\": 98.33891026,\n        \"num_unique_values\": 4408,\n        \"samples\": [\n          33.70594801,\n          90.03712486,\n          25.05576326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Electric power consumption (kWh per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4325.196010328713,\n        \"min\": 22.48184434,\n        \"max\": 54799.17471,\n        \"num_unique_values\": 3644,\n        \"samples\": [\n          2658.418628118782,\n          206.2771632,\n          8174.408162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Energy use (kg of oil equivalent per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4760.337500642505,\n        \"min\": 9.579196003,\n        \"max\": 197209.00845990723,\n        \"num_unique_values\": 3807,\n        \"samples\": [\n          695.1348324,\n          565.3273918,\n          3205.328271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable electricity output (% of total electricity output)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.55740141599933,\n        \"min\": -2.76281104889535,\n        \"max\": 100.47239374276964,\n        \"num_unique_values\": 4436,\n        \"samples\": [\n          21.57118997,\n          99.89101477,\n          24.69010449387077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable energy consumption (% of total final energy consumption)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.609065972127446,\n        \"min\": 0.0,\n        \"max\": 98.34,\n        \"num_unique_values\": 3997,\n        \"samples\": [\n          79.02,\n          21.19,\n          77.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population growth (annual %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4711193274065608,\n        \"min\": -6.852117676,\n        \"max\": 19.36042866,\n        \"num_unique_values\": 5523,\n        \"samples\": [\n          0.025087267,\n          -1.666382643,\n          0.76783354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP per capita (current US$)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22028.338711031764,\n        \"min\": 110.4608747,\n        \"max\": 204097.114,\n        \"num_unique_values\": 5351,\n        \"samples\": [\n          1492.377075,\n          4359.7924,\n          15595.6365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2 emissions (metric tons per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.890510317312629,\n        \"min\": 0.0,\n        \"max\": 47.65696201,\n        \"num_unique_values\": 4359,\n        \"samples\": [\n          8.860393054,\n          0.215113481,\n          0.332610017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRMWhH1v-Zs9",
        "outputId": "b6d3c26e-cdc8-415d-8916-b86faf5c3d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              "1    4733\n",
              "0     853\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "I4BWaj-E-eEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Cluster'], axis=1)\n",
        "y = df['Cluster']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxDF8SDw-pHP",
        "outputId": "ad4fd3be-2598-4f04-a5bf-5d7c261bc190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4468, 13)\n",
            "X_test shape: (1118, 13)\n",
            "y_train shape: (4468,)\n",
            "y_test shape: (1118,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "2rN_nMYH-uKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "JCYnEA6S-sX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqwZOMJW-5hN",
        "outputId": "7afb1352-0bef-4386-8b1c-f8b81ba7c0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9935897435897436\n",
            "Sensitivity: 0.998960498960499\n",
            "Precision: 0.998960498960499\n",
            "Recall: 0.998960498960499\n",
            "F1 Score: 0.998960498960499\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.998960498960499\n",
            "Sensitivity: 0.9935897435897436\n",
            "Precision: 0.9935897435897436\n",
            "Recall: 0.9935897435897436\n",
            "F1 Score: 0.9935897435897436\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Overall accuracy: 0.998211091234347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"\\nFold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E4Bui2q-_9J",
        "outputId": "eb969755-c999-466d-8363-64fff404b8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9935897435897436\n",
            "Sensitivity: 0.998960498960499\n",
            "Precision: 0.998960498960499\n",
            "Recall: 0.998960498960499\n",
            "F1 Score: 0.998960498960499\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.998960498960499\n",
            "Sensitivity: 0.9935897435897436\n",
            "Precision: 0.9935897435897436\n",
            "Recall: 0.9935897435897436\n",
            "F1 Score: 0.9935897435897436\n",
            "Accuracy: 0.998211091234347\n",
            "\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.994475138121547\n",
            "Sensitivity: 0.9989316239316239\n",
            "Precision: 0.9989316239316239\n",
            "Recall: 0.9989316239316239\n",
            "F1 Score: 0.9989316239316239\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989316239316239\n",
            "Sensitivity: 0.994475138121547\n",
            "Precision: 0.994475138121547\n",
            "Recall: 0.994475138121547\n",
            "F1 Score: 0.994475138121547\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9989406779661016\n",
            "Precision: 1.0\n",
            "Recall: 0.9989406779661016\n",
            "F1 Score: 0.9994700582935877\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989406779661016\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9942528735632183\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9971181556195965\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9989384288747346\n",
            "Precision: 1.0\n",
            "Recall: 0.9989384288747346\n",
            "F1 Score: 0.9994689325544344\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989384288747346\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9943181818181818\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9971509971509972\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9976129763422581\n",
            "Sensitivity: 0.9991542459465919\n",
            "Precision: 0.9995784245784247\n",
            "Recall: 0.9991542459465919\n",
            "F1 Score: 0.9993662227480289\n",
            "Accuracy: 0.9989260141286957\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9991542459465919\n",
            "Sensitivity: 0.9976129763422581\n",
            "Precision: 0.9953271874185381\n",
            "Recall: 0.9976129763422581\n",
            "F1 Score: 0.9964668068963768\n",
            "Accuracy: 0.9989260141286957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DT"
      ],
      "metadata": {
        "id": "BKlyp9PP_HSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s4DIowP_Gz1",
        "outputId": "8877cfad-aab8-42c1-b55b-fc041fac46f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9885714285714285\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9978813559322034\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9989395546129375\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9885714285714285\n",
            "Precision: 1.0\n",
            "Recall: 0.9885714285714285\n",
            "F1 Score: 0.9942528735632185\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Overall accuracy: 0.9982094897045658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = dt.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohZpTCqA_THf",
        "outputId": "b4122cbd-4fd2-4b27-f1a8-89fc730b6abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9871794871794872\n",
            "Sensitivity: 0.998960498960499\n",
            "Precision: 0.9979231568016614\n",
            "Recall: 0.998960498960499\n",
            "F1 Score: 0.9984415584415584\n",
            "Accuracy: 0.9973166368515206\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.998960498960499\n",
            "Sensitivity: 0.9871794871794872\n",
            "Precision: 0.9935483870967742\n",
            "Recall: 0.9871794871794872\n",
            "F1 Score: 0.990353697749196\n",
            "Accuracy: 0.9973166368515206\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9834254143646409\n",
            "Sensitivity: 0.9989316239316239\n",
            "Precision: 0.9968017057569296\n",
            "Recall: 0.9989316239316239\n",
            "F1 Score: 0.9978655282817502\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989316239316239\n",
            "Sensitivity: 0.9834254143646409\n",
            "Precision: 0.994413407821229\n",
            "Recall: 0.9834254143646409\n",
            "F1 Score: 0.9888888888888889\n",
            "Accuracy: 0.9964189794091316\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9942196531791907\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9989417989417989\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9994706193753309\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9942196531791907\n",
            "Precision: 1.0\n",
            "Recall: 0.9942196531791907\n",
            "F1 Score: 0.9971014492753623\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9978925184404637\n",
            "Precision: 1.0\n",
            "Recall: 0.9978925184404637\n",
            "F1 Score: 0.998945147679325\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9978925184404637\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9882352941176471\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9940828402366864\n",
            "Accuracy: 0.9982094897045658\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9942857142857143\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9989395546129375\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9994694960212203\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9942857142857143\n",
            "Precision: 1.0\n",
            "Recall: 0.9942857142857143\n",
            "F1 Score: 0.9971346704871061\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9918220538018068\n",
            "Sensitivity: 0.9991569282665174\n",
            "Precision: 0.9985212432226656\n",
            "Recall: 0.9991569282665174\n",
            "F1 Score: 0.9988384699598368\n",
            "Accuracy: 0.9980309191339568\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9991569282665174\n",
            "Sensitivity: 0.9918220538018068\n",
            "Precision: 0.9952394178071302\n",
            "Recall: 0.9918220538018068\n",
            "F1 Score: 0.9935123093274478\n",
            "Accuracy: 0.9980309191339568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NN"
      ],
      "metadata": {
        "id": "hQJFvjml_eRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHcQyciY_cpR",
        "outputId": "71fb0233-8e43-4a41-ebe8-b459c8f771ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9968152866242038\n",
            "Precision: 1.0\n",
            "Recall: 0.9968152866242038\n",
            "F1 Score: 0.9984051036682616\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9968152866242038\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9831460674157303\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9915014164305949\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Overall accuracy: 0.9973142345568488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YRfNrT__lTD",
        "outputId": "cf390307-68f7-49a3-e91a-eaafee96c6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9927234927234927\n",
            "Precision: 1.0\n",
            "Recall: 0.9927234927234927\n",
            "F1 Score: 0.9963484611371936\n",
            "Accuracy: 0.9937388193202147\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9927234927234927\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9570552147239264\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9780564263322884\n",
            "Accuracy: 0.9937388193202147\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9447513812154696\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9894291754756871\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9946865037194473\n",
            "Accuracy: 0.991047448522829\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9447513812154696\n",
            "Precision: 1.0\n",
            "Recall: 0.9447513812154696\n",
            "F1 Score: 0.9715909090909092\n",
            "Accuracy: 0.991047448522829\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9942196531791907\n",
            "Sensitivity: 0.9978813559322034\n",
            "Precision: 0.9989395546129375\n",
            "Recall: 0.9978813559322034\n",
            "F1 Score: 0.9984101748807631\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9978813559322034\n",
            "Sensitivity: 0.9942196531791907\n",
            "Precision: 0.9885057471264368\n",
            "Recall: 0.9942196531791907\n",
            "F1 Score: 0.9913544668587896\n",
            "Accuracy: 0.9973142345568488\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9884088514225501\n",
            "Precision: 1.0\n",
            "Recall: 0.9884088514225501\n",
            "F1 Score: 0.9941706412294649\n",
            "Accuracy: 0.990152193375112\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9884088514225501\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9385474860335196\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9682997118155621\n",
            "Accuracy: 0.990152193375112\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9968152866242038\n",
            "Precision: 1.0\n",
            "Recall: 0.9968152866242038\n",
            "F1 Score: 0.9984051036682616\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9968152866242038\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9831460674157303\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9915014164305949\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.987794206878932\n",
            "Sensitivity: 0.99516579734049\n",
            "Precision: 0.997673746017725\n",
            "Recall: 0.99516579734049\n",
            "F1 Score: 0.996404176927026\n",
            "Accuracy: 0.9939133860663706\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.99516579734049\n",
            "Sensitivity: 0.987794206878932\n",
            "Precision: 0.9734509030599225\n",
            "Recall: 0.987794206878932\n",
            "F1 Score: 0.9801605861056288\n",
            "Accuracy: 0.9939133860663706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "SvXFj_4c_3gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "kUdAH5H9_0s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier (GaussianNB for continuous features)\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the entire training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=nb.classes_)\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(nb.classes_):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgfpW7CuADim",
        "outputId": "18f8ac67-12e8-4708-b3c0-0ca36fd172e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8535031847133758\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5591054313099042\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7172131147540984\n",
            "Accuracy: 0.8764547896150403\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8535031847133758\n",
            "Precision: 1.0\n",
            "Recall: 0.8535031847133758\n",
            "F1 Score: 0.9209621993127148\n",
            "Accuracy: 0.8764547896150403\n",
            "\n",
            "Overall accuracy: 0.8764547896150403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nb.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nb.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FanhhR7AAHee",
        "outputId": "301bd3b8-a36e-4728-adc7-55874a84186c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8295218295218295\n",
            "Precision: 1.0\n",
            "Recall: 0.8295218295218295\n",
            "F1 Score: 0.9068181818181817\n",
            "Accuracy: 0.853309481216458\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8295218295218295\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.4875\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6554621848739496\n",
            "Accuracy: 0.853309481216458\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8450854700854701\n",
            "Precision: 1.0\n",
            "Recall: 0.8450854700854701\n",
            "F1 Score: 0.9160393746381007\n",
            "Accuracy: 0.8701880035810206\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8450854700854701\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5552147239263804\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7140039447731755\n",
            "Accuracy: 0.8701880035810206\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8336864406779662\n",
            "Precision: 1.0\n",
            "Recall: 0.8336864406779662\n",
            "F1 Score: 0.9093009820912767\n",
            "Accuracy: 0.8594449418084154\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8336864406779662\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5242424242424243\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6878727634194831\n",
            "Accuracy: 0.8594449418084154\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8366701791359326\n",
            "Precision: 1.0\n",
            "Recall: 0.8366701791359326\n",
            "F1 Score: 0.9110728628800918\n",
            "Accuracy: 0.8612354521038496\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8366701791359326\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5201238390092879\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6843177189409368\n",
            "Accuracy: 0.8612354521038496\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8535031847133758\n",
            "Precision: 1.0\n",
            "Recall: 0.8535031847133758\n",
            "F1 Score: 0.9209621993127148\n",
            "Accuracy: 0.8764547896150403\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8535031847133758\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5591054313099042\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7172131147540984\n",
            "Accuracy: 0.8764547896150403\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8396934208269148\n",
            "Precision: 1.0\n",
            "Recall: 0.8396934208269148\n",
            "F1 Score: 0.9128387201480731\n",
            "Accuracy: 0.8641265336649567\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.8396934208269148\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5292372836975993\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6917739453523286\n",
            "Accuracy: 0.8641265336649567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Linear"
      ],
      "metadata": {
        "id": "AVFSLNAmAW9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "D2FtK5RIAN3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM linear classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "labels = y.unique()\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Print evaluation metrics\n",
        "# Iterate over indices and labels simultaneously\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_wjh9ejAdU2",
        "outputId": "b79ab91a-9c88-4a81-affb-c38d3b93b0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Overall accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a linear kernel\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyfJnsP5AjjX",
        "outputId": "cbc1d782-71e4-45d0-c476-90d9800140e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9958419958419958\n",
            "Precision: 1.0\n",
            "Recall: 0.9958419958419958\n",
            "F1 Score: 0.9979166666666666\n",
            "Accuracy: 0.9964221824686941\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9958419958419958\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.975\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9873417721518987\n",
            "Accuracy: 0.9964221824686941\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9834254143646409\n",
            "Sensitivity: 0.9957264957264957\n",
            "Precision: 0.9967914438502674\n",
            "Recall: 0.9957264957264957\n",
            "F1 Score: 0.9962586851950829\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9957264957264957\n",
            "Sensitivity: 0.9834254143646409\n",
            "Precision: 0.978021978021978\n",
            "Recall: 0.9834254143646409\n",
            "F1 Score: 0.9807162534435261\n",
            "Accuracy: 0.9937332139659804\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9942196531791907\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9989417989417989\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9994706193753309\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9942196531791907\n",
            "Precision: 1.0\n",
            "Recall: 0.9942196531791907\n",
            "F1 Score: 0.9971014492753623\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9821428571428571\n",
            "Sensitivity: 0.9968387776606955\n",
            "Precision: 0.9968387776606955\n",
            "Recall: 0.9968387776606955\n",
            "F1 Score: 0.9968387776606955\n",
            "Accuracy: 0.9946284691136974\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9968387776606955\n",
            "Sensitivity: 0.9821428571428571\n",
            "Precision: 0.9821428571428571\n",
            "Recall: 0.9821428571428571\n",
            "F1 Score: 0.9821428571428571\n",
            "Accuracy: 0.9946284691136974\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9919575849373377\n",
            "Sensitivity: 0.9976814538458374\n",
            "Precision: 0.9985144040905525\n",
            "Recall: 0.9976814538458374\n",
            "F1 Score: 0.9980969497795551\n",
            "Accuracy: 0.9967777220801309\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9976814538458374\n",
            "Sensitivity: 0.9919575849373377\n",
            "Precision: 0.9870329670329671\n",
            "Recall: 0.9919575849373377\n",
            "F1 Score: 0.9894604664027288\n",
            "Accuracy: 0.9967777220801309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Non-linear"
      ],
      "metadata": {
        "id": "XsdHJOTlA0Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (e.g., 'rbf')\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# Fit the classifier on the entire dataset\n",
        "svm.fit(X, y)\n",
        "\n",
        "# Predict on the same dataset\n",
        "y_pred = svm.predict(X)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "print(\"Evaluation Metrics for SVM Non-Linear Classification:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvjcqWTCAyNe",
        "outputId": "42fb9a45-ef08-4ac6-b599-0d34bc61f852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for SVM Non-Linear Classification:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9980984576378619\n",
            "Sensitivity: 0.9859320046893317\n",
            "Precision: 0.9894117647058823\n",
            "Recall: 0.9859320046893317\n",
            "F1 Score: 0.9876688197298884\n",
            "Accuracy: 0.9962406015037594\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9980984576378619\n",
            "Sensitivity: 0.9859320046893317\n",
            "Precision: 0.9894117647058823\n",
            "Recall: 0.9859320046893317\n",
            "F1 Score: 0.9876688197298884\n",
            "Accuracy: 0.9962406015037594\n",
            "\n",
            "Overall accuracy: 0.9962406015037594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (RBF)\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "id": "yN6tL7nTA-Ps",
        "outputId": "1e349369-3c50-4d07-e718-33527680b1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9871794871794872\n",
            "Sensitivity: 0.997920997920998\n",
            "Precision: 0.997920997920998\n",
            "Recall: 0.997920997920998\n",
            "F1 Score: 0.997920997920998\n",
            "Accuracy: 0.9964221824686941\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.997920997920998\n",
            "Sensitivity: 0.9871794871794872\n",
            "Precision: 0.9871794871794872\n",
            "Recall: 0.9871794871794872\n",
            "F1 Score: 0.9871794871794872\n",
            "Accuracy: 0.9964221824686941\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9834254143646409\n",
            "Sensitivity: 0.9978632478632479\n",
            "Precision: 0.9967982924226254\n",
            "Recall: 0.9978632478632479\n",
            "F1 Score: 0.997330485851575\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9978632478632479\n",
            "Sensitivity: 0.9834254143646409\n",
            "Precision: 0.9888888888888889\n",
            "Recall: 0.9834254143646409\n",
            "F1 Score: 0.9861495844875346\n",
            "Accuracy: 0.9955237242614146\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9826589595375722\n",
            "Sensitivity: 0.9989406779661016\n",
            "Precision: 0.9968287526427061\n",
            "Recall: 0.9989406779661016\n",
            "F1 Score: 0.9978835978835978\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989406779661016\n",
            "Sensitivity: 0.9826589595375722\n",
            "Precision: 0.9941520467836257\n",
            "Recall: 0.9826589595375722\n",
            "F1 Score: 0.9883720930232557\n",
            "Accuracy: 0.9964189794091316\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9761904761904762\n",
            "Sensitivity: 0.9968387776606955\n",
            "Precision: 0.9957894736842106\n",
            "Recall: 0.9968387776606955\n",
            "F1 Score: 0.9963138493944182\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9968387776606955\n",
            "Sensitivity: 0.9761904761904762\n",
            "Precision: 0.9820359281437125\n",
            "Recall: 0.9761904761904762\n",
            "F1 Score: 0.9791044776119404\n",
            "Accuracy: 0.9937332139659804\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9942857142857143\n",
            "Sensitivity: 0.9989384288747346\n",
            "Precision: 0.9989384288747346\n",
            "Recall: 0.9989384288747346\n",
            "F1 Score: 0.9989384288747346\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9989384288747346\n",
            "Sensitivity: 0.9942857142857143\n",
            "Precision: 0.9942857142857143\n",
            "Recall: 0.9942857142857143\n",
            "F1 Score: 0.9942857142857143\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9847480103115782\n",
            "Sensitivity: 0.9981004260571555\n",
            "Precision: 0.997255189109055\n",
            "Recall: 0.9981004260571555\n",
            "F1 Score: 0.9976774719850647\n",
            "Accuracy: 0.9960615179619572\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9981004260571555\n",
            "Sensitivity: 0.9847480103115782\n",
            "Precision: 0.9893084130562858\n",
            "Recall: 0.9847480103115782\n",
            "F1 Score: 0.9870182713175865\n",
            "Accuracy: 0.9960615179619572\n"
          ]
        }
      ]
    }
  ]
}