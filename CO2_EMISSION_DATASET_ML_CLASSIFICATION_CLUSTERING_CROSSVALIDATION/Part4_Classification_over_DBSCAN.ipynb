{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IghfpWw0r5qj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/DBSCAN_clustered_df2.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Q80xMWX6vABC",
        "outputId": "2e26030d-5bd3-4f93-f60e-4a0e5b7b5934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Access to electricity (% of population)  \\\n",
              "0  2000                                 4.446891   \n",
              "1  2001                                 9.294527   \n",
              "2  2002                                14.133616   \n",
              "3  2003                                18.971165   \n",
              "4  2004                                23.814182   \n",
              "\n",
              "   Agricultural land (% of land area)  \\\n",
              "0                           57.945817   \n",
              "1                           57.947350   \n",
              "2                           57.939684   \n",
              "3                           58.083805   \n",
              "4                           58.151266   \n",
              "\n",
              "   Annual freshwater withdrawals, total (% of internal resources)  \\\n",
              "0                                          43.015907                \n",
              "1                                          43.015907                \n",
              "2                                          43.015907                \n",
              "3                                          43.015907                \n",
              "4                                          43.015907                \n",
              "\n",
              "   Arable land (% of land area)  Forest area (% of land area)  \\\n",
              "0                     11.779587                      1.852782   \n",
              "1                     11.779587                      1.852782   \n",
              "2                     11.771921                      1.852782   \n",
              "3                     11.916042                      1.852782   \n",
              "4                     11.983503                      1.852782   \n",
              "\n",
              "   Electric power consumption (kWh per capita)  \\\n",
              "0                                  1586.591120   \n",
              "1                                  1587.375364   \n",
              "2                                  1649.718098   \n",
              "3                                  1738.666619   \n",
              "4                                  1841.168267   \n",
              "\n",
              "   Energy use (kg of oil equivalent per capita)  \\\n",
              "0                                    985.730004   \n",
              "1                                   1011.679617   \n",
              "2                                   1034.410867   \n",
              "3                                   1010.524231   \n",
              "4                                   1121.869767   \n",
              "\n",
              "   Renewable electricity output (% of total electricity output)  \\\n",
              "0                                          74.989094              \n",
              "1                                          72.811460              \n",
              "2                                          79.063971              \n",
              "3                                          70.249729              \n",
              "4                                          70.890841              \n",
              "\n",
              "   Renewable energy consumption (% of total final energy consumption)  \\\n",
              "0                                              44.99                    \n",
              "1                                              45.60                    \n",
              "2                                              37.83                    \n",
              "3                                              36.66                    \n",
              "4                                              44.24                    \n",
              "\n",
              "   Population growth (annual %)  GDP per capita (current US$)  \\\n",
              "0                      1.443803                    182.174037   \n",
              "1                      0.742517                    182.174037   \n",
              "2                      6.449321                    182.174037   \n",
              "3                      7.541019                    199.643228   \n",
              "4                      3.933178                    221.830531   \n",
              "\n",
              "   CO2 emissions (metric tons per capita)  Cluster  \n",
              "0                                0.055167        0  \n",
              "1                                0.055293        0  \n",
              "2                                0.066810        0  \n",
              "3                                0.073005        0  \n",
              "4                                0.054867        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39d36028-55fa-4774-ae10-6bb26e4b5660\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Access to electricity (% of population)</th>\n",
              "      <th>Agricultural land (% of land area)</th>\n",
              "      <th>Annual freshwater withdrawals, total (% of internal resources)</th>\n",
              "      <th>Arable land (% of land area)</th>\n",
              "      <th>Forest area (% of land area)</th>\n",
              "      <th>Electric power consumption (kWh per capita)</th>\n",
              "      <th>Energy use (kg of oil equivalent per capita)</th>\n",
              "      <th>Renewable electricity output (% of total electricity output)</th>\n",
              "      <th>Renewable energy consumption (% of total final energy consumption)</th>\n",
              "      <th>Population growth (annual %)</th>\n",
              "      <th>GDP per capita (current US$)</th>\n",
              "      <th>CO2 emissions (metric tons per capita)</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>4.446891</td>\n",
              "      <td>57.945817</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1586.591120</td>\n",
              "      <td>985.730004</td>\n",
              "      <td>74.989094</td>\n",
              "      <td>44.99</td>\n",
              "      <td>1.443803</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055167</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>9.294527</td>\n",
              "      <td>57.947350</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1587.375364</td>\n",
              "      <td>1011.679617</td>\n",
              "      <td>72.811460</td>\n",
              "      <td>45.60</td>\n",
              "      <td>0.742517</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055293</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>14.133616</td>\n",
              "      <td>57.939684</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.771921</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1649.718098</td>\n",
              "      <td>1034.410867</td>\n",
              "      <td>79.063971</td>\n",
              "      <td>37.83</td>\n",
              "      <td>6.449321</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.066810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>18.971165</td>\n",
              "      <td>58.083805</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.916042</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1738.666619</td>\n",
              "      <td>1010.524231</td>\n",
              "      <td>70.249729</td>\n",
              "      <td>36.66</td>\n",
              "      <td>7.541019</td>\n",
              "      <td>199.643228</td>\n",
              "      <td>0.073005</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>23.814182</td>\n",
              "      <td>58.151266</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.983503</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1841.168267</td>\n",
              "      <td>1121.869767</td>\n",
              "      <td>70.890841</td>\n",
              "      <td>44.24</td>\n",
              "      <td>3.933178</td>\n",
              "      <td>221.830531</td>\n",
              "      <td>0.054867</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39d36028-55fa-4774-ae10-6bb26e4b5660')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39d36028-55fa-4774-ae10-6bb26e4b5660 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39d36028-55fa-4774-ae10-6bb26e4b5660');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-520cc61d-d621-466e-9159-e9e38419e7df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-520cc61d-d621-466e-9159-e9e38419e7df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-520cc61d-d621-466e-9159-e9e38419e7df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5586,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2000,\n        \"max\": 2020,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2000,\n          2017,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Access to electricity (% of population)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.009307167116457,\n        \"min\": 0.796382964,\n        \"max\": 100.0,\n        \"num_unique_values\": 3517,\n        \"samples\": [\n          18.72191048,\n          99.64420319,\n          57.97229767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agricultural land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.08418270854103,\n        \"min\": 0.448717949,\n        \"max\": 85.48737287,\n        \"num_unique_values\": 4205,\n        \"samples\": [\n          38.38383838,\n          60.42062566,\n          39.54077135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Annual freshwater withdrawals, total (% of internal resources)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 550.832181089681,\n        \"min\": 0.02036036,\n        \"max\": 7750.0,\n        \"num_unique_values\": 2609,\n        \"samples\": [\n          0.985916515,\n          318.3845455,\n          5832.045455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Arable land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.513691681893778,\n        \"min\": 0.043140638,\n        \"max\": 64.14688484,\n        \"num_unique_values\": 3804,\n        \"samples\": [\n          7.869067642,\n          44.19781931,\n          28.97936625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forest area (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.913181689877433,\n        \"min\": 0.0,\n        \"max\": 98.33891026,\n        \"num_unique_values\": 4408,\n        \"samples\": [\n          33.70594801,\n          90.03712486,\n          25.05576326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Electric power consumption (kWh per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4325.196010328713,\n        \"min\": 22.48184434,\n        \"max\": 54799.17471,\n        \"num_unique_values\": 3644,\n        \"samples\": [\n          2658.418628118782,\n          206.2771632,\n          8174.408162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Energy use (kg of oil equivalent per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4760.337500642505,\n        \"min\": 9.579196003,\n        \"max\": 197209.00845990723,\n        \"num_unique_values\": 3807,\n        \"samples\": [\n          695.1348324,\n          565.3273918,\n          3205.328271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable electricity output (% of total electricity output)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.55740141599933,\n        \"min\": -2.76281104889535,\n        \"max\": 100.47239374276964,\n        \"num_unique_values\": 4436,\n        \"samples\": [\n          21.57118997,\n          99.89101477,\n          24.69010449387077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable energy consumption (% of total final energy consumption)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.609065972127446,\n        \"min\": 0.0,\n        \"max\": 98.34,\n        \"num_unique_values\": 3997,\n        \"samples\": [\n          79.02,\n          21.19,\n          77.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population growth (annual %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4711193274065608,\n        \"min\": -6.852117676,\n        \"max\": 19.36042866,\n        \"num_unique_values\": 5523,\n        \"samples\": [\n          0.025087267,\n          -1.666382643,\n          0.76783354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP per capita (current US$)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22028.338711031764,\n        \"min\": 110.4608747,\n        \"max\": 204097.114,\n        \"num_unique_values\": 5351,\n        \"samples\": [\n          1492.377075,\n          4359.7924,\n          15595.6365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2 emissions (metric tons per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.890510317312629,\n        \"min\": 0.0,\n        \"max\": 47.65696201,\n        \"num_unique_values\": 4359,\n        \"samples\": [\n          8.860393054,\n          0.215113481,\n          0.332610017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 2,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEDCRzIvGpb",
        "outputId": "5e0584fa-0dc1-42ec-9e4b-c2e9980f698e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              " 0    5546\n",
              " 2      24\n",
              " 1      13\n",
              "-1       3\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers using Trimming method\n",
        "def remove_outliers_trimming(df, column, trim_fraction=0.05):\n",
        "    # Calculate trimming bounds\n",
        "    lower_bound = df[column].quantile(trim_fraction)\n",
        "    upper_bound = df[column].quantile(1 - trim_fraction)\n",
        "    # Remove rows where data points are outside the trimming bounds\n",
        "    df_trimmed = df[(df[column] >= lower_bound)]\n",
        "    return df_trimmed\n",
        "df_trimmed = remove_outliers_trimming(df, 'Cluster')"
      ],
      "metadata": {
        "id": "Hmd-JCH4vLi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.boxplot(df['Cluster']) # Old Data with Outliers\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(df_trimmed['Cluster']) # Trimmed data\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "EU-IZmnZvb7_",
        "outputId": "b442ec5a-4c97-48d3-9c7a-51da91e7c043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABSoAAAEwCAYAAACwrk9QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4vUlEQVR4nO3df1yV9f3/8ecB5aAtjjIVOHlSzKazFJwmYa1okYh+/MT2WfNHC8Nf5ae85Y6uybawVo1qq2iLRWV+UMsflY22ciyj0Kmo8wcrdzO/oRQqHNKW5wgZMDjfP8prngQ9HIGLA4/77Xbd4npf7+s6r2vndvP22vNcPyxer9crAAAAAAAAADBRiNkFAAAAAAAAAABBJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMF0Pswvo7JqamlRZWamLL75YFovF7HIAAABazev16uTJk7Lb7QoJ4XfqYEM/CgAAgp2//ShB5XlUVlbK4XCYXQYAAMAFO3z4sAYOHGh2GWgl+lEAANBVnK8fJag8j4svvljSl/9DRkREmFwNAABA63k8HjkcDqOvQXChHwUAAMHO336UoPI8Tt9eExERQWMIAACCGrcNByf6UQAA0FWcrx/lIUUAAAAAAAAATEdQCQAAAAAAAMB0BJUAAAAAAAAATEdQCQAAAAAAAMB0BJUAAAAAAAAATEdQCQAm2r59u5KSkoxl+/btZpcEAACAboR+FEBnEjRBZXZ2tq666ipdfPHFGjBggNLS0nTgwIHz7vfKK69o+PDhCg8P18iRI7Vhw4YOqBYAzi8pKUlLlizxGVuyZImSkpLMKQgAurn26je9Xq+ysrIUExOjXr16KTk5WR9++GF7nQYA+I1+FEBnEzRB5aZNm3TXXXdp+/bt2rhxoxoaGjRhwgTV1ta2uM+2bds0ffp0zZ49W3v37lVaWprS0tK0b9++DqwcAM729eZv3Lhx59wOAGh/7dVvPvbYY/rd736nvLw87dixQxdddJFSUlL0xRdfdMRpAUCz6EcBdEYWr9frNbuIQBw7dkwDBgzQpk2bdN111zU7Z+rUqaqtrdUbb7xhjF199dWKj49XXl6eX5/j8Xhks9nkdrsVERHRJrUD6N62b99u/HKdk5Oj+Ph4Y1tpaakWLlwoSXrkkUd09dVXm1AhgK6GfiYwbdFver1e2e12LVq0SIsXL5Ykud1uRUVFKT8/X9OmTTtvHXx/ANoa/SiAjuZvPxM0V1R+ndvtliRFRka2OKekpETJyck+YykpKSopKWlxn7q6Onk8Hp8FANrSmbfXnNkUfn3967fhAAA6Vlv0m+Xl5XK5XD5zbDabEhISWuxJ6UcBtDf6UQCdVVAGlU1NTVq4cKGuueYaXXnllS3Oc7lcioqK8hmLioqSy+VqcZ/s7GzZbDZjcTgcbVY3AJzp67fXnDZ69OgOrgQA8HVt1W+e/m9relL6UQAdhX4UQGcTlEHlXXfdpX379mnt2rVtfuzMzEy53W5jOXz4cJt/BgBI0s6dO5sd37t3bwdXAgD4uvbsN8+HfhRAR6EfBdDZBF1Qeffdd+uNN97Qu+++q4EDB55zbnR0tKqrq33GqqurFR0d3eI+VqtVERERPgsAtKVHHnnE+Lu0tNRn25nrZ84DAHSctuw3T/+3NT0p/SiA9kY/CqCz6mF2Af7yer1asGCB/vjHP6q4uFixsbHn3ScxMVFFRUXGg4AlaePGjUpMTGzHSgHg3M58IPnpf59Gjx591i/XPLgcADpWe/SbsbGxio6OVlFRkfHcN4/Hox07dmj+/PntcRoAcF70owA6q6C5ovKuu+7Siy++qNWrV+viiy+Wy+WSy+XSqVOnjDnp6enKzMw01u+55x4VFhbq8ccf1wcffKD7779fu3bt0t13323GKQCAobi42Gf9603h17cDANpfe/SbFotFCxcu1EMPPaQ//elPev/995Weni673a60tLSOPkUAMNCPAuiMgiaofOaZZ+R2u5WUlKSYmBhjWbdunTGnoqJCVVVVxvr48eO1evVqPffcc4qLi9Orr76qgoKCcz4QHQA6SnFx8Vm30zzyyCM0hQBgkvbqN++9914tWLBA8+bN01VXXaWamhoVFhYqPDy8Q88PAL6OfhRAZ2Pxer1es4vozDwej2w2m9xuN88HAgAAQYl+Jrjx/QEAgGDnbz8TNFdUAgAAAAAAAOi6CCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAASZs3b9aUKVNkt9tlsVhUUFBwzvm33367LBbLWcsVV1xhzLn//vvP2j58+PB2PhMAAIDgRFAJAAAASKqtrVVcXJxyc3P9mv/UU0+pqqrKWA4fPqzIyEjdcsstPvOuuOIKn3lbtmxpj/IBAACCXg+zCwAAAAA6g9TUVKWmpvo932azyWazGesFBQX67LPPlJGR4TOvR48eio6ObrM6AQAAuiquqAQAAADawAsvvKDk5GQNGjTIZ/zDDz+U3W7XkCFDdOutt6qiouKcx6mrq5PH4/FZAAAAugOCSgAAAOACVVZW6i9/+YvmzJnjM56QkKD8/HwVFhbqmWeeUXl5ub773e/q5MmTLR4rOzvbuFrTZrPJ4XC0d/kAAACdAkElAAAAcIFWrFihPn36KC0tzWc8NTVVt9xyi0aNGqWUlBRt2LBBJ06c0Msvv9zisTIzM+V2u43l8OHD7Vw9AABA58AzKgEAAIAL4PV6tXz5ct12220KCws759w+ffroW9/6lsrKylqcY7VaZbVa27pMAACATo8rKgEAAIALsGnTJpWVlWn27NnnnVtTU6ODBw8qJiamAyoDAAAILgSVAAAAgL4MEUtLS1VaWipJKi8vV2lpqfHym8zMTKWnp5+13wsvvKCEhARdeeWVZ21bvHixNm3apI8++kjbtm3T97//fYWGhmr69Ontei4AAADBiFu/AQAAAEm7du3SDTfcYKw7nU5J0syZM5Wfn6+qqqqz3tjtdru1fv16PfXUU80e88iRI5o+fbo+/fRT9e/fX9dee622b9+u/v37t9+JAAAABCmL1+v1ml1EZ+bxeGSz2eR2uxUREWF2OQAAAK1GPxPc+P4AAECw87efCapbvzdv3qwpU6bIbrfLYrGooKDgnPOLi4tlsVjOWlwuV8cUDAAAAAAAAMAvQRVU1tbWKi4uTrm5ua3a78CBA6qqqjKWAQMGtFOFAAAAAAAAAAIRVM+oTE1NVWpqaqv3GzBggPr06ePX3Lq6OtXV1RnrHo+n1Z8HAAAAAAAAoHWC6orKQMXHxysmJkY33XSTtm7des652dnZstlsxuJwODqoSgAAAAAAAKD76tJBZUxMjPLy8rR+/XqtX79eDodDSUlJ2rNnT4v7ZGZmyu12G8vhw4c7sGIAAAAAAACgewqqW79ba9iwYRo2bJixPn78eB08eFBPPvmkVq1a1ew+VqtVVqu1o0oEAAAAAAAAoC5+RWVzxo0bp7KyMrPLAAAAAAAAAHCGbhdUlpaWKiYmxuwyAAAAAAAAAJwhqG79rqmp8bkasry8XKWlpYqMjNSll16qzMxMHT16VCtXrpQk5eTkKDY2VldccYW++OILLVu2TO+8847eeusts04BAAAAAAAAQDOCKqjctWuXbrjhBmPd6XRKkmbOnKn8/HxVVVWpoqLC2F5fX69Fixbp6NGj6t27t0aNGqW3337b5xgAAAAAAAAAzGfxer1es4vozDwej2w2m9xutyIiIswuBwAAoNXoZ4Ib3x8AAAh2/vYz3e4ZlQAAAAAAAAA6H4JKAAAAAAAAAKYjqAQAAAAAAABgOoJKAAAAAAAAAKYjqAQAAAAAAABgOoJKAAAAAAAAAKYjqAQAAAAAAABgOoJKAAAAAAAAAKYjqAQAAAAAAABgOoJKAAAAAAAAAKYjqAQAAAAkbd68WVOmTJHdbpfFYlFBQcE55xcXF8tisZy1uFwun3m5ubkaPHiwwsPDlZCQoJ07d7bjWQAAAAQvgkoAAABAUm1treLi4pSbm9uq/Q4cOKCqqipjGTBggLFt3bp1cjqdWrp0qfbs2aO4uDilpKTok08+aevyAQAAgl4PswsAAAAAOoPU1FSlpqa2er8BAwaoT58+zW574oknNHfuXGVkZEiS8vLy9Oabb2r58uVasmTJhZQLAADQ5XBFJQAAAHAB4uPjFRMTo5tuuklbt241xuvr67V7924lJycbYyEhIUpOTlZJSUmLx6urq5PH4/FZAAAAugOCSgAAACAAMTExysvL0/r167V+/Xo5HA4lJSVpz549kqTjx4+rsbFRUVFRPvtFRUWd9RzLM2VnZ8tmsxmLw+Fo1/MAAADoLLj1GwAAAAjAsGHDNGzYMGN9/PjxOnjwoJ588kmtWrUq4ONmZmbK6XQa6x6Ph7ASAAB0CwSVAAAAQBsZN26ctmzZIknq16+fQkNDVV1d7TOnurpa0dHRLR7DarXKarW2a50AAACdEbd+AwAAAG2ktLRUMTExkqSwsDCNGTNGRUVFxvampiYVFRUpMTHRrBIBAAA6La6oBAAAACTV1NSorKzMWC8vL1dpaakiIyN16aWXKjMzU0ePHtXKlSslSTk5OYqNjdUVV1yhL774QsuWLdM777yjt956yziG0+nUzJkzNXbsWI0bN045OTmqra013gIOAACA/yCoBAAAACTt2rVLN9xwg7F++jmRM2fOVH5+vqqqqlRRUWFsr6+v16JFi3T06FH17t1bo0aN0ttvv+1zjKlTp+rYsWPKysqSy+VSfHy8CgsLz3rBDgAAACSL1+v1ml1EZ+bxeGSz2eR2uxUREWF2OQAAAK1GPxPc+P4AAECw87ef4RmVAAAAAAAAAExHUAkAAAAAAADAdASVAAAAAAAAAExHUAkAAAAAAADAdASVAAAAAAAAAExHUAkAAAAAAADAdASVAAAAAAAAAExHUAkAAAAAAADAdASVAAAAAAAAAExHUAkAJjp06JC+973vKSkpSd/73vd06NAhs0sCAAAAAMAUQRVUbt68WVOmTJHdbpfFYlFBQcF59ykuLtZ3vvMdWa1WDR06VPn5+e1eJwD4IykpSbNmzVJTU5MkqampSbNmzVJSUpK5hQEAAAAAYIKgCipra2sVFxen3Nxcv+aXl5dr8uTJuuGGG1RaWqqFCxdqzpw5+utf/9rOlQLAuZ0ZRvbs2VOzZs1Sz549m90OAAAAAEB30MPsAlojNTVVqampfs/Py8tTbGysHn/8cUnSt7/9bW3ZskVPPvmkUlJS2qtMADinM2/vXr16tex2uyQpPT1dlZWVmjFjhjFvyJAhptQIAAAAAEBHC6orKlurpKREycnJPmMpKSkqKSlpcZ+6ujp5PB6fBQDa0pw5cyR9eSXl6ZDyNLvdblxZeXoeAAAAAADdQZcOKl0ul6KionzGoqKi5PF4dOrUqWb3yc7Ols1mMxaHw9ERpQLoRk4/k/K2225rdvu0adN85gEAAAAA0B106aAyEJmZmXK73cZy+PBhs0sC0MWEhHz5T++qVaua3b527VqfeQAAAAAAdAdd+v8FR0dHq7q62mesurpaERER6tWrV7P7WK1WRURE+CwA0JaWLVsmSWpoaFBlZaXPtsrKSjU0NPjMAwAAAACgOwiql+m0VmJiojZs2OAztnHjRiUmJppUEQDI5wU5M2bMUM+ePTVt2jStXbvWCCm/Pg8AAAAAgK4uqK6orKmpUWlpqUpLSyVJ5eXlKi0tVUVFhaQvb9tOT0835t955506dOiQ7r33Xn3wwQf6wx/+oJdfflk/+clPzCgfAAzFxcXG3w0NDVq1apVPSHnmdgAAAAAAuoOgCip37dql0aNHa/To0ZIkp9Op0aNHKysrS5JUVVVlhJaSFBsbqzfffFMbN25UXFycHn/8cS1btkwpKSmm1A8AZyouLtby5cuNZ1GGhIRo+fLlhJQAAAAAgG7J4vV6vWYX0Zl5PB7ZbDa53W6eVwkAAIIS/Uxw4/sDAADBzt9+JqiuqAQAAADay+bNmzVlyhTZ7XZZLBYVFBScc/5rr72mm266Sf3791dERIQSExP117/+1WfO/fffL4vF4rMMHz68Hc8CAAAgeBFUAgAAAJJqa2sVFxen3Nxcv+Zv3rxZN910kzZs2KDdu3frhhtu0JQpU7R3716feVdccYWqqqqMZcuWLe1RPgAAQNDr0m/9BgAAAPyVmpqq1NRUv+fn5OT4rP/617/W66+/rj//+c/GM9UlqUePHoqOjvb7uHV1daqrqzPWPR6P3/sCAAAEM66oBAAAANpAU1OTTp48qcjISJ/xDz/8UHa7XUOGDNGtt97q8/LH5mRnZ8tmsxmLw+Foz7IBAAA6DYJKAAAAoA389re/VU1NjX70ox8ZYwkJCcrPz1dhYaGeeeYZlZeX67vf/a5OnjzZ4nEyMzPldruN5fDhwx1RPgAAgOm49RsAAAC4QKtXr9YDDzyg119/XQMGDDDGz7yVfNSoUUpISNCgQYP08ssva/bs2c0ey2q1ymq1tnvNAAAAnQ1BJQAAAHAB1q5dqzlz5uiVV15RcnLyOef26dNH3/rWt1RWVtZB1QEAAAQPbv0GAAAAArRmzRplZGRozZo1mjx58nnn19TU6ODBg4qJiemA6gAAAIILV1QCAAAA+jJEPPNKx/LycpWWlioyMlKXXnqpMjMzdfToUa1cuVLSl7d7z5w5U0899ZQSEhLkcrkkSb169ZLNZpMkLV68WFOmTNGgQYNUWVmppUuXKjQ0VNOnT+/4EwQAAOjkuKISAAAAkLRr1y6NHj1ao0ePliQ5nU6NHj1aWVlZkqSqqiqfN3Y/99xz+ve//6277rpLMTExxnLPPfcYc44cOaLp06dr2LBh+tGPfqRvfvOb2r59u/r379+xJwcAABAELF6v12t2EZ2Zx+ORzWaT2+1WRESE2eUAAAC0Gv1McOP7AwAAwc7ffoYrKgEAAAAAAACYjqASAAAAAAAAgOlaHVQ2NjZq8+bNOnHiRDuUAwAAAPiP3hQAAKDraHVQGRoaqgkTJuizzz5rj3oAAAAAv9GbAgAAdB0B3fp95ZVX6tChQ21dCwAAANBq9KYAAABdQ0BB5UMPPaTFixfrjTfeUFVVlTwej88CAAAAdBR6UwAAgK7B4vV6va3dKSTkP/mmxWIx/vZ6vbJYLGpsbGyb6joBf1+fDgAA0Fl19X6mq/emXf37AwAAXZ+//UyPQA7+7rvvBlwYAAAA0JboTQEAALqGgILK66+/vq3rAAAAAAJCbwoAANA1BPSMSkn629/+ph//+McaP368jh49KklatWqVtmzZ0mbFAQAAAP6gNwUAAAh+AQWV69evV0pKinr16qU9e/aorq5OkuR2u/XrX/+6TQsEAAAAzoXeFAAAoGsI+K3feXl5ev7559WzZ09j/JprrtGePXvarDgAAADgfOhNAQAAuoaAgsoDBw7ouuuuO2vcZrPpxIkTF1oTAAAA4Dd6UwAAgK4hoKAyOjpaZWVlZ41v2bJFQ4YMueCiAAAAAH/RmwIAAHQNAQWVc+fO1T333KMdO3bIYrGosrJSL730khYvXqz58+e3dY0AAABAi+hNAQAAuoYegey0ZMkSNTU16cYbb9Tnn3+u6667TlarVYsXL9aCBQvaukYAAACgRfSmAAAAXYPF6/V6A925vr5eZWVlqqmp0YgRI/SNb3yjLWvrFDwej2w2m9xutyIiIswuBwAAoNW6Sz/TVXvT7vL9AQCArsvffiagW79nzZqlkydPKiwsTCNGjNC4ceP0jW98Q7W1tZo1a1bARQMAAACtRW8KAADQNQQUVK5YsUKnTp06a/zUqVNauXLlBRcFAAAA+IveFAAAoGto1TMqPR6PvF6vvF6vTp48qfDwcGNbY2OjNmzYoAEDBrR5kQAAAMDX0ZsCwIU7dOiQ5syZo6amJoWEhGjZsmUaMmSI2WUB6KZadUVlnz59FBkZKYvFom9961vq27evsfTr10+zZs3SXXfd1V61SpJyc3M1ePBghYeHKyEhQTt37mxxbn5+viwWi89yZgMLAACA4NXWvenmzZs1ZcoU2e12WSwWFRQUnHef4uJifec735HVatXQoUOVn59/1pzW9K8A0JGSkpI0a9YsNTU1SZKampo0a9YsJSUlmVsYgG6rVVdUvvvuu/J6vfre976n9evXKzIy0tgWFhamQYMGyW63t3mRp61bt05Op1N5eXlKSEhQTk6OUlJSdODAgRZ/LY+IiNCBAweMdYvF0m71AQAAoOO0dW9aW1uruLg4zZo1Sz/4wQ/OO7+8vFyTJ0/WnXfeqZdeeklFRUWaM2eOYmJilJKSIimw/hUAOsKZYWTPnj112223adWqVWpoaDC2FxcXm1McgG4roLd+f/zxx7r00ks7PPRLSEjQVVddpaefflrSl7/2OBwOLViwQEuWLDlrfn5+vhYuXKgTJ04E/Jm8ZREAAAS7rt7PtEdvarFY9Mc//lFpaWktzvnZz36mN998U/v27TPGpk2bphMnTqiwsFBS6/vX5nT17w9Axzt06JDxsrHVq1f7/KhTWVmpGTNmSJKWL1/ObeAA2kS7vvV7//792rp1q7Gem5ur+Ph4zZgxQ5999lkghzyv+vp67d69W8nJycZYSEiIkpOTVVJS0uJ+NTU1GjRokBwOh26++Wb985//POfn1NXVyePx+CwAAADovMzoTSWppKTEpzeVpJSUFKM3DbR/pR8F0N7mzJkj6csrKb9+5bndblfPnj195gFARwkoqPzpT39qNEzvv/++nE6nJk2apPLycjmdzjYt8LTjx4+rsbFRUVFRPuNRUVFyuVzN7jNs2DAtX75cr7/+ul588UU1NTVp/PjxOnLkSIufk52dLZvNZiwOh6NNzwMAAABty4zeVJJcLlezvanH49GpU6cC6l8l+lEA7e/0Mylvu+22ZrdPmzbNZx4AdJSAgsry8nKNGDFCkrR+/XpNmTJFv/71r5Wbm6u//OUvbVrghUhMTFR6erri4+N1/fXX67XXXlP//v317LPPtrhPZmam3G63sRw+fLgDKwYAAEBrBUtv6i/6UQDtLSTkyyhg1apVzW5fu3atzzwA6CgB/asTFhamzz//XJL09ttva8KECZKkyMjIdrs1pV+/fgoNDVV1dbXPeHV1taKjo/06Rs+ePTV69GiVlZW1OMdqtSoiIsJnAQAAQOdlRm8qSdHR0c32phEREerVq1fA/Sv9KID2tmzZMklSQ0ODKisrfbZVVlYaL9Q5PQ8AOkpAQeW1114rp9OpBx98UDt37tTkyZMlSf/v//0/DRw4sE0LPC0sLExjxoxRUVGRMdbU1KSioiIlJib6dYzGxka9//77iomJaZcaAQAA0PHM6E2lL+/eObM3laSNGzcavWlb9K8A0B7OfEHOjBkzdNNNN+mFF17QTTfdZLxI5+vzAKAjBBRUPv300+rRo4deffVVPfPMM7rkkkskSX/5y180ceLENi3wTE6nU88//7xWrFih/fv3a/78+aqtrVVGRoYkKT09XZmZmcb8X/3qV3rrrbd06NAh7dmzRz/+8Y/18ccf80BgAACALqStetOamhqVlpaqtLRU0pe3lJeWlqqiokLSl7dkp6enG/PvvPNOHTp0SPfee68++OAD/eEPf9DLL7+sn/zkJ8ac8/WvAGCW4uJi4++GhgatWrXKuJLy69sBoKP0CGSnSy+9VG+88cZZ408++eQFF3QuU6dO1bFjx5SVlSWXy6X4+HgVFhYaDyivqKjweYbGZ599prlz58rlcqlv374aM2aMtm3bZjzDCAAAAMGvrXrTXbt26YYbbjDWT7+IZ+bMmcrPz1dVVZURWkpSbGys3nzzTf3kJz/RU089pYEDB2rZsmVKSUkx5pyvfwUAMxUXF+vQoUOaM2eOmpqaFBISomXLlnElJQDTWLxer7e1O53ZoDXn0ksvDbigzsbj8chms8ntdvN8IAAAEJS6ej/T1XvTrv79AQCArs/ffiagKyoHDx4si8XS4vbGxsZADgsAAAC0Gr0pAABA1xBQULl3716f9YaGBu3du1dPPPGEHn744TYpDAAAAPAHvSkAAEDXEFBQGRcXd9bY2LFjZbfb9Zvf/EY/+MEPLrgwAAAAwB/0pgAAAF1DQG/9bsmwYcP097//vS0PCQAAAASE3hQAACC4BHRFpcfj8Vn3er2qqqrS/fffr8svv7xNCgMAAAD8QW8KAADQNQQUVPbp0+esB5Z7vV45HA6tXbu2TQoDAAAA/EFvCgAA0DUEFFS+++67PushISHq37+/hg4dqh49AjokAAAAEBB6UwAAgK4hoM7t+uuvb+s6AAAAgIDQmwIAAHQNfgeVf/rTn/w+6H//938HVAwAAADgD3pTAACArsfvoDItLc2veRaLRY2NjYHWAwAAAJwXvSkAAEDX43dQ2dTU1J51AAAAAH6jNwUAAOh6Qloz+Z133tGIESPk8XjO2uZ2u3XFFVfob3/7W5sVBwAAALSE3hQAAKBraVVQmZOTo7lz5yoiIuKsbTabTXfccYeeeOKJNisOAAAAaAm9KQAAQNfSqqDyH//4hyZOnNji9gkTJmj37t0XXBQAAABwPvSmAAAAXUurgsrq6mr17Nmzxe09evTQsWPHLrgoAAAA4HzoTQEAALqWVgWVl1xyifbt29fi9vfee08xMTEXXBQAAABwPvSmAAAAXUurgspJkybpvvvu0xdffHHWtlOnTmnp0qX6r//6rzYrDgAAAGgJvSkAAEDXYvF6vV5/J1dXV+s73/mOQkNDdffdd2vYsGGSpA8++EC5ublqbGzUnj17FBUV1W4FdzSPxyObzSa3293sg9oBAAA6u67az3SX3rSrfn8AAKD78Lef6dGag0ZFRWnbtm2aP3++MjMzdTrjtFgsSklJUW5ubtA3ggAAAAgO9KYAAABdS6uCSkkaNGiQNmzYoM8++0xlZWXyer26/PLL1bdv3/aoDwAAAGgRvSkAAEDX0eqg8rS+ffvqqquuastaAAAAgIDQmwIAAAS/Vr1MBwAAAOjqcnNzNXjwYIWHhyshIUE7d+5scW5SUpIsFstZy+TJk405t99++1nbJ06c2BGnAgAAEFQCvqISAAAA6GrWrVsnp9OpvLw8JSQkKCcnRykpKTpw4IAGDBhw1vzXXntN9fX1xvqnn36quLg43XLLLT7zJk6cqP/7v/8z1q1Wa/udBAAAQJDiikoAAADgK0888YTmzp2rjIwMjRgxQnl5eerdu7eWL1/e7PzIyEhFR0cby8aNG9W7d++zgkqr1eozj2doAgAAnI2gEgAAAJBUX1+v3bt3Kzk52RgLCQlRcnKySkpK/DrGCy+8oGnTpumiiy7yGS8uLtaAAQM0bNgwzZ8/X59++mmLx6irq5PH4/FZAAAAugOCSgAAAEDS8ePH1djYqKioKJ/xqKgouVyu8+6/c+dO7du3T3PmzPEZnzhxolauXKmioiI9+uij2rRpk1JTU9XY2NjscbKzs2Wz2YzF4XAEflIAAABBhGdUAgAAAG3ghRde0MiRIzVu3Dif8WnTphl/jxw5UqNGjdJll12m4uJi3XjjjWcdJzMzU06n01j3eDyElQAAoFvgikoAAABAUr9+/RQaGqrq6mqf8erqakVHR59z39raWq1du1azZ88+7+cMGTJE/fr1U1lZWbPbrVarIiIifBYAAIDugKASAAAAkBQWFqYxY8aoqKjIGGtqalJRUZESExPPue8rr7yiuro6/fjHPz7v5xw5ckSffvqpYmJiLrhmAACAroSgEgAAAPiK0+nU888/rxUrVmj//v2aP3++amtrlZGRIUlKT09XZmbmWfu98MILSktL0ze/+U2f8ZqaGv30pz/V9u3b9dFHH6moqEg333yzhg4dqpSUlA45JwAAgGDBMyoBAACAr0ydOlXHjh1TVlaWXC6X4uPjVVhYaLxgp6KiQiEhvr/1HzhwQFu2bNFbb7111vFCQ0P13nvvacWKFTpx4oTsdrsmTJigBx98UFartUPOCQAAIFhYvF6v1+wiOjOPxyObzSa3283zgQAAQFCinwlufH8AACDY+dvPBN2t37m5uRo8eLDCw8OVkJCgnTt3nnP+K6+8ouHDhys8PFwjR47Uhg0bOqhSAAAAAAAAAP4KqqBy3bp1cjqdWrp0qfbs2aO4uDilpKTok08+aXb+tm3bNH36dM2ePVt79+5VWlqa0tLStG/fvg6uHAAAAAAAAMC5BNWt3wkJCbrqqqv09NNPS/ryLYwOh0MLFizQkiVLzpo/depU1dbW6o033jDGrr76asXHxysvL8+vz+RWGwAAEOzoZ4Ib3x8AAAh2/vYzQfMynfr6eu3evdvnLYshISFKTk5WSUlJs/uUlJTI6XT6jKWkpKigoKDFz6mrq1NdXZ2x7vF4LqzwIFBWVqby8nKzy0CAPv/8cx08eNDsMoBu77LLLlPv3r3NLgMBio2N1dChQ80uAwAAAOjWgiaoPH78uBobG403Lp4WFRWlDz74oNl9XC5Xs/NdLleLn5Odna0HHnjgwgsOIr///e/1j3/8w+wyAAAwTVxcnJ566imzywAAAAC6taAJKjtKZmamz1WYHo9HDofDxIra34IFC7iiMohxRSXQOXBFZXCLjY01uwQAAACg2wuaoLJfv34KDQ1VdXW1z3h1dbWio6Ob3Sc6OrpV8yXJarXKarVeeMFBZOjQodzuBgAAAAAAAFMFzVu/w8LCNGbMGBUVFRljTU1NKioqUmJiYrP7JCYm+syXpI0bN7Y4HwAAAAAAAIA5guaKSklyOp2aOXOmxo4dq3HjxiknJ0e1tbXKyMiQJKWnp+uSSy5Rdna2JOmee+7R9ddfr8cff1yTJ0/W2rVrtWvXLj333HNmngYAAAAAAACArwmqoHLq1Kk6duyYsrKy5HK5FB8fr8LCQuOFORUVFQoJ+c9FouPHj9fq1av1y1/+Uj//+c91+eWXq6CgQFdeeaVZpwAAAAAAAACgGRav1+s1u4jOzOPxyGazye12KyIiwuxyAAAAWo1+Jrjx/QEAgGDnbz8TNM+oBAAAAAAAANB1EVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAAAAAADTEVQCAAAAAAAAMB1BJQAAAHCG3NxcDR48WOHh4UpISNDOnTtbnJufny+LxeKzhIeH+8zxer3KyspSTEyMevXqpeTkZH344YftfRoAAABBh6ASAAAA+Mq6devkdDq1dOlS7dmzR3FxcUpJSdEnn3zS4j4RERGqqqoylo8//thn+2OPPabf/e53ysvL044dO3TRRRcpJSVFX3zxRXufDgAAQFAhqAQAAAC+8sQTT2ju3LnKyMjQiBEjlJeXp969e2v58uUt7mOxWBQdHW0sUVFRxjav16ucnBz98pe/1M0336xRo0Zp5cqVqqysVEFBQQecEQAAQPAgqAQAAAAk1dfXa/fu3UpOTjbGQkJClJycrJKSkhb3q6mp0aBBg+RwOHTzzTfrn//8p7GtvLxcLpfL55g2m00JCQktHrOurk4ej8dnAQAA6A4IKgEAAABJx48fV2Njo88VkZIUFRUll8vV7D7Dhg3T8uXL9frrr+vFF19UU1OTxo8fryNHjkiSsV9rjpmdnS2bzWYsDofjQk8NAAAgKBBUAgAAAAFKTExUenq64uPjdf311+u1115T//799eyzzwZ8zMzMTLndbmM5fPhwG1YMAADQeRFUAgAAAJL69eun0NBQVVdX+4xXV1crOjrar2P07NlTo0ePVllZmSQZ+7XmmFarVRERET4LAABAd0BQCQAAAEgKCwvTmDFjVFRUZIw1NTWpqKhIiYmJfh2jsbFR77//vmJiYiRJsbGxio6O9jmmx+PRjh07/D4mAABAd9HD7AIAAACAzsLpdGrmzJkaO3asxo0bp5ycHNXW1iojI0OSlJ6erksuuUTZ2dmSpF/96le6+uqrNXToUJ04cUK/+c1v9PHHH2vOnDmSvnwj+MKFC/XQQw/p8ssvV2xsrO677z7Z7XalpaWZdZoAAACdEkElAAAA8JWpU6fq2LFjysrKksvlUnx8vAoLC42X4VRUVCgk5D83JX322WeaO3euXC6X+vbtqzFjxmjbtm0aMWKEMefee+9VbW2t5s2bpxMnTujaa69VYWGhwsPDO/z8AAAAOjOL1+v1ml1EZ+bxeGSz2eR2u3k+EAAACEr0M8GN7w8AAAQ7f/sZnlEJAAAAAAAAwHQElQAAAAAAAABMR1AJAAAAAAAAwHQElQAAAAAAAABMR1AJAAAAAAAAwHQElQAAAAAAAABMR1AJAAAAAAAAwHQElQAAAAAAAABMR1AJAAAAAAAAwHQElQAAAAAAAABMFzRB5b/+9S/deuutioiIUJ8+fTR79mzV1NScc5+kpCRZLBaf5c477+ygigEAAAAAAAD4q4fZBfjr1ltvVVVVlTZu3KiGhgZlZGRo3rx5Wr169Tn3mzt3rn71q18Z6717927vUgEAAAAAAAC0UlAElfv371dhYaH+/ve/a+zYsZKk3//+95o0aZJ++9vfym63t7hv7969FR0d3VGlAgAAAAAAAAhAUNz6XVJSoj59+hghpSQlJycrJCREO3bsOOe+L730kvr166crr7xSmZmZ+vzzz885v66uTh6Px2cBAAAAAAAA0L6C4opKl8ulAQMG+Iz16NFDkZGRcrlcLe43Y8YMDRo0SHa7Xe+9955+9rOf6cCBA3rttdda3Cc7O1sPPPBAm9UOAAAAAAAA4PxMDSqXLFmiRx999Jxz9u/fH/Dx582bZ/w9cuRIxcTE6MYbb9TBgwd12WWXNbtPZmamnE6nse7xeORwOAKuAQAAAAAAAMD5mRpULlq0SLfffvs55wwZMkTR0dH65JNPfMb//e9/61//+lernj+ZkJAgSSorK2sxqLRarbJarX4fEwAAAAAAAMCFMzWo7N+/v/r373/eeYmJiTpx4oR2796tMWPGSJLeeecdNTU1GeGjP0pLSyVJMTExAdULAAAAAAAAoH0Exct0vv3tb2vixImaO3eudu7cqa1bt+ruu+/WtGnTjDd+Hz16VMOHD9fOnTslSQcPHtSDDz6o3bt366OPPtKf/vQnpaen67rrrtOoUaPMPB0AAAAAAAAAXxMUQaX05du7hw8frhtvvFGTJk3Stddeq+eee87Y3tDQoAMHDhhv9Q4LC9Pbb7+tCRMmaPjw4Vq0aJH+53/+R3/+85/NOgUAAAAAAAAALQiKt35LUmRkpFavXt3i9sGDB8vr9RrrDodDmzZt6ojSAAAAAAAAAFygoLmiEgAAAOgIubm5Gjx4sMLDw5WQkGA8Wqg5zz//vL773e+qb9++6tu3r5KTk8+af/vtt8tisfgsEydObO/TAAAACDoElQAAAMBX1q1bJ6fTqaVLl2rPnj2Ki4tTSkqKPvnkk2bnFxcXa/r06Xr33XdVUlIih8OhCRMm6OjRoz7zJk6cqKqqKmNZs2ZNR5wOAABAUCGoBAAAAL7yxBNPaO7cucrIyNCIESOUl5en3r17a/ny5c3Of+mll/S///u/io+P1/Dhw7Vs2TI1NTWpqKjIZ57ValV0dLSx9O3btyNOBwAAIKgQVAIAAACS6uvrtXv3biUnJxtjISEhSk5OVklJiV/H+Pzzz9XQ0KDIyEif8eLiYg0YMEDDhg3T/Pnz9emnn7Z4jLq6Onk8Hp8FAACgOyCoBAAAACQdP35cjY2NioqK8hmPioqSy+Xy6xg/+9nPZLfbfcLOiRMnauXKlSoqKtKjjz6qTZs2KTU1VY2Njc0eIzs7WzabzVgcDkfgJwUAABBEguat3wAAAEBn9sgjj2jt2rUqLi5WeHi4MT5t2jTj75EjR2rUqFG67LLLVFxcrBtvvPGs42RmZsrpdBrrHo+HsBIAAHQLXFEJAAAASOrXr59CQ0NVXV3tM15dXa3o6Ohz7vvb3/5WjzzyiN566y2NGjXqnHOHDBmifv36qaysrNntVqtVERERPgsAAEB3QFAJAAAASAoLC9OYMWN8XoRz+sU4iYmJLe732GOP6cEHH1RhYaHGjh173s85cuSIPv30U8XExLRJ3QAAAF0FQSUAAADwFafTqeeff14rVqzQ/v37NX/+fNXW1iojI0OSlJ6erszMTGP+o48+qvvuu0/Lly/X4MGD5XK55HK5VFNTI0mqqanRT3/6U23fvl0fffSRioqKdPPNN2vo0KFKSUkx5RwBAAA6K55RCQAAAHxl6tSpOnbsmLKysuRyuRQfH6/CwkLjBTsVFRUKCfnPb/3PPPOM6uvr9cMf/tDnOEuXLtX999+v0NBQvffee1qxYoVOnDghu92uCRMm6MEHH5TVau3QcwMAAOjsLF6v12t2EZ2Zx+ORzWaT2+3m+UAAACAo0c8EN74/AAAQ7PztZ7j1GwAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpCCoBAAAAAAAAmI6gEgAAAAAAAIDpephdAAB0Z6dOndKzzz6rI0eOaODAgbrjjjvUq1cvs8sCAAAAAKDDEVQCgEl+8YtfaOvWrcb6rl27VFBQoGuuuUYPP/ywiZUBAAAAANDxgubW74cffljjx49X79691adPH7/28Xq9ysrKUkxMjHr16qXk5GR9+OGH7VsoAPjhdEjZs2dPzZgxQy+++KJmzJihnj17auvWrfrFL35hdokA0G3l5uZq8ODBCg8PV0JCgnbu3HnO+a+88oqGDx+u8PBwjRw5Uhs2bPDZTk8KAADgn6AJKuvr63XLLbdo/vz5fu/z2GOP6Xe/+53y8vK0Y8cOXXTRRUpJSdEXX3zRjpUCwLmdOnXKCCnffPNNzZs3TwMHDtS8efP05ptvGmHlqVOnzC4VALqddevWyel0aunSpdqzZ4/i4uKUkpKiTz75pNn527Zt0/Tp0zV79mzt3btXaWlpSktL0759+4w59KQAAAD+sXi9Xq/ZRbRGfn6+Fi5cqBMnTpxzntfrld1u16JFi7R48WJJktvtVlRUlPLz8zVt2rRm96urq1NdXZ2x7vF45HA45Ha7FRER0WbnAaD7ysnJUUFBgWbMmKF58+adtf3ZZ5/VmjVrlJaWpoULF3Z8gQC6HI/HI5vNRj/jh4SEBF111VV6+umnJUlNTU1yOBxasGCBlixZctb8qVOnqra2Vm+88YYxdvXVVys+Pl55eXkB9aTdtR8tKytTeXm52WUgAJ9//rkOHjxodhkAJF122WXq3bu32WUgQLGxsRo6dKjZZbQLf/vRLvuMyvLycrlcLiUnJxtjNptNCQkJKikpaTGozM7O1gMPPNBRZQLoho4cOSJJmjRpUrPbJ02apDVr1hjzAAAdo76+Xrt371ZmZqYxFhISouTkZJWUlDS7T0lJiZxOp89YSkqKCgoKJAXWk3bXfvT3v/+9/vGPf5hdBgAApomLi9NTTz1ldhmm6rJBpcvlkiRFRUX5jEdFRRnbmpOZmenTbJ7+BRsA2srAgQO1a9cubdiwodkrKk8/22zgwIEdXRoAdGvHjx9XY2Njs/3jBx980Ow+LpfrnP1mID1pd+1HFyxYwBWVQYorKoHOgysqg1tsbKzZJZjO1KByyZIlevTRR885Z//+/Ro+fHgHVSRZrVZZrdYO+zwA3c8dd9yhgoICvfLKK7r99tsVFhZmbKuvr9err75qzAMAdD/dtR8dOnRol73dDQAA+MfUoHLRokW6/fbbzzlnyJAhAR07OjpaklRdXa2YmBhjvLq6WvHx8QEdEwDaQq9evXTNNddo69atmjx5sn74wx9q0qRJ2rBhg1599VU1NDTommuuUa9evcwuFQC6lX79+ik0NFTV1dU+49XV1UZv+XXR0dHnnE9PCgAA4D9T3/rdv39/DR8+/JzLmVcatUZsbKyio6NVVFRkjHk8Hu3YsUOJiYltdQoAEJCHH35Y11xzjRoaGrRmzRrddtttWrNmjRFSPvzww2aXCADdTlhYmMaMGePTPzY1NamoqKjF/jExMdFnviRt3LjRmE9PCgAA4L+geUZlRUWF/vWvf6miokKNjY0qLS2V9OUtIt/4xjckScOHD1d2dra+//3vy2KxaOHChXrooYd0+eWXKzY2Vvfdd5/sdrvS0tLMOxEA+MrDDz+sU6dO6dlnn9WRI0c0cOBA3XHHHVxJCQAmcjqdmjlzpsaOHatx48YpJydHtbW1ysjIkCSlp6frkksuUXZ2tiTpnnvu0fXXX6/HH39ckydP1tq1a7Vr1y4999xzkkRPCgAA0ApBE1RmZWVpxYoVxvro0aMlSe+++66SkpIkSQcOHJDb7Tbm3HvvvaqtrdW8efN04sQJXXvttSosLFR4eHiH1g4ALenVq5cWLlxodhkAgK9MnTpVx44dU1ZWllwul+Lj41VYWGi8DKeiokIhIf+5KWn8+PFavXq1fvnLX+rnP/+5Lr/8chUUFOjKK6805tCTAgAA+Mfi9Xq9ZhfRmXk8HtlsNrndbkVERJhdDgAAQKvRzwQ3vj8AABDs/O1nTH1GJQAAAAAAAABIBJUAAAAAAAAAOgGCSgAAAAAAAACmI6gEAAAAAAAAYLqgeeu3WU6/a8jj8ZhcCQAAQGBO9zG8QzE40Y8CAIBg528/SlB5HidPnpQkORwOkysBAAC4MCdPnpTNZjO7DLQS/SgAAOgqztePWrz8tH5OTU1Nqqys1MUXXyyLxWJ2OQC6II/HI4fDocOHDysiIsLscgB0QV6vVydPnpTdbldICE/+CTb0owDaG/0ogPbmbz9KUAkAJvN4PLLZbHK73TSGAAAA6HD0owA6C35SBwAAAAAAAGA6gkoAAAAAAAAApiOoBACTWa1WLV26VFar1exSAAAA0A3RjwLoLHhGJQAAAAAAAADTcUUlAAAAAAAAANMRVAIAAAAAAAAwHUElAAAAAAAAANMRVAIAAAAAAAAwHUElAAAAAAAAANMRVAIAAAAAAAAwHUElAAAAAAAAANMRVAIAAAAAAAAw3f8HPgV4LJsX+rgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvKK2_1JvzEB",
        "outputId": "c2950500-09ce-40a6-c23d-21907df8b1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              " 0    5546\n",
              " 2      24\n",
              " 1      13\n",
              "-1       3\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_trimmed['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZamsAv9PwJiV",
        "outputId": "9f222ec1-1b9f-46c4-c5f8-8e2fee7d2cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              "0    5546\n",
              "2      24\n",
              "1      13\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_trimmed.copy()"
      ],
      "metadata": {
        "id": "8ClOX0iBwOgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_YScd4twXVj",
        "outputId": "696d0e5d-21eb-4949-ef74-e7755eda7191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cluster\n",
              "0    5546\n",
              "2      24\n",
              "1      13\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "HzwjajVQwaUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Cluster'], axis=1)\n",
        "y = df['Cluster']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXsGDztLwtdy",
        "outputId": "b08931ae-b261-4fdf-d8a5-cd9004e5dfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4466, 13)\n",
            "X_test shape: (1117, 13)\n",
            "y_train shape: (4466,)\n",
            "y_test shape: (1117,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "8qcs3sAww4rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "hMZ7wXSTw0Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUaNvvhswxzt",
        "outputId": "55f24eee-da2d-4d75-c41c-f1c4c7e86986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Overall accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"\\nFold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpHjYLsjxArl",
        "outputId": "17faafac-b340-46ce-bdd9-53dc9e36c600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DT"
      ],
      "metadata": {
        "id": "5NgJViS2xqRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4AHPI3xxJhB",
        "outputId": "93fb0fc5-984d-4166-c4ab-e662ec16aecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Overall accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = dt.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jx1mm8fxy7X",
        "outputId": "9ac1c0b0-8c89-4b6e-97ad-ecb805094ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8888888888888888\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9990982867448152\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9995489400090213\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8\n",
            "Precision: 1.0\n",
            "Recall: 0.8\n",
            "F1 Score: 0.888888888888889\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9777777777777779\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9998196573489629\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9999097880018042\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.96\n",
            "Precision: 1.0\n",
            "Recall: 0.96\n",
            "F1 Score: 0.9777777777777779\n",
            "Accuracy: 0.9998209489704566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NN"
      ],
      "metadata": {
        "id": "lxECUqX7yAmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS0ld-8qx8nA",
        "outputId": "794e314e-8153-47d8-aefd-0fddadea0db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.36363636363636365\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9937050359712231\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9968425800631484\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.125\n",
            "Precision: 1.0\n",
            "Recall: 0.125\n",
            "F1 Score: 0.2222222222222222\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Overall accuracy: 0.9937275985663082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxI8_2t3yJjf",
        "outputId": "d6dac019-8a48-4bc3-e615-d5687f771d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.16666666666666666\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9955197132616488\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9977548271216884\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Accuracy: 0.9955237242614146\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9954873646209387\n",
            "Precision: 1.0\n",
            "Recall: 0.9954873646209387\n",
            "F1 Score: 0.9977385798281322\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9973045822102425\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5714285714285714\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7272727272727273\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9982014388489209\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.7142857142857143\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8333333333333333\n",
            "Accuracy: 0.9955237242614146\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9991007194244604\n",
            "Precision: 1.0\n",
            "Recall: 0.9991007194244604\n",
            "F1 Score: 0.9995501574448944\n",
            "Accuracy: 0.9991039426523297\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9991039426523297\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9991015274034142\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.75\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8571428571428571\n",
            "Accuracy: 0.9991039426523297\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.36363636363636365\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9937050359712231\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9968425800631484\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.125\n",
            "Precision: 1.0\n",
            "Recall: 0.125\n",
            "F1 Score: 0.2222222222222222\n",
            "Accuracy: 0.9937275985663082\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.7060606060606062\n",
            "Sensitivity: 0.9989176168090796\n",
            "Precision: 0.9978449498465742\n",
            "Recall: 0.9989176168090796\n",
            "F1 Score: 0.9983772288915727\n",
            "Accuracy: 0.9967757979482934\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9994609164420485\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9142857142857143\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9454545454545455\n",
            "Accuracy: 0.9967757979482934\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9994605932504669\n",
            "Sensitivity: 0.625\n",
            "Precision: 0.6928571428571428\n",
            "Recall: 0.625\n",
            "F1 Score: 0.5825396825396825\n",
            "Accuracy: 0.9967757979482934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "ikcvw7dnyS7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "QQYekVwGyQI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier (GaussianNB for continuous features)\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the entire training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=nb.classes_)\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(nb.classes_):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBF5D4nfyigC",
        "outputId": "e329517a-4e1d-4ebe-c306-11aa87776035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9972850678733032\n",
            "Precision: 1.0\n",
            "Recall: 0.9972850678733032\n",
            "F1 Score: 0.9986406887177164\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9972924187725631\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.7272727272727273\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8421052631578948\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Overall accuracy: 0.9973118279569892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nb.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nb.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE_nqcE5ymkS",
        "outputId": "1767c40a-6b0f-4299-f823-a8af525a8415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9990990990990991\n",
            "Precision: 1.0\n",
            "Recall: 0.9990990990990991\n",
            "F1 Score: 0.9995493465525012\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9991023339317774\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.75\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8571428571428571\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9981949458483754\n",
            "Precision: 1.0\n",
            "Recall: 0.9981949458483754\n",
            "F1 Score: 0.999096657633243\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9982014388489209\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.7142857142857143\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8333333333333333\n",
            "Accuracy: 0.9982094897045658\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9982014388489209\n",
            "Precision: 1.0\n",
            "Recall: 0.9982014388489209\n",
            "F1 Score: 0.9990999099909991\n",
            "Accuracy: 0.9982078853046595\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9982078853046595\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9982030548068284\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.6\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7499999999999999\n",
            "Accuracy: 0.9982078853046595\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9972850678733032\n",
            "Precision: 1.0\n",
            "Recall: 0.9972850678733032\n",
            "F1 Score: 0.9986406887177164\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9972924187725631\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.7272727272727273\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8421052631578948\n",
            "Accuracy: 0.9973118279569892\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9985561103339397\n",
            "Precision: 1.0\n",
            "Recall: 0.9985561103339397\n",
            "F1 Score: 0.999277320578892\n",
            "Accuracy: 0.9985667895636995\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9985667895636995\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.998559849272018\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.7583116883116883\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8565162907268171\n",
            "Accuracy: 0.9985667895636995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Linear"
      ],
      "metadata": {
        "id": "JS67R6vNyzOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "7-0_2cKcywSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM linear classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "labels = y.unique()\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Print evaluation metrics\n",
        "# Iterate over indices and labels simultaneously\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C53EbRdSy6Cc",
        "outputId": "0d9c2dd0-269e-43d4-f25b-eb2789496895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Overall accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a linear kernel\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu9m0PH1y8cg",
        "outputId": "55113ae7-fef2-4602-ec34-c6e31fad7409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8888888888888888\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9990982867448152\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9995489400090213\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8\n",
            "Precision: 1.0\n",
            "Recall: 0.8\n",
            "F1 Score: 0.888888888888889\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9777777777777779\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9998196573489629\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9999097880018042\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.96\n",
            "Precision: 1.0\n",
            "Recall: 0.96\n",
            "F1 Score: 0.9777777777777779\n",
            "Accuracy: 0.9998209489704566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Non-Linear"
      ],
      "metadata": {
        "id": "0CzyGW31zGif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (e.g., 'rbf')\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# Fit the classifier on the entire dataset\n",
        "svm.fit(X, y)\n",
        "\n",
        "# Predict on the same dataset\n",
        "y_pred = svm.predict(X)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "print(\"Evaluation Metrics for SVM Non-Linear Classification:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU87RXDdzKsE",
        "outputId": "82249db5-2d7c-41b3-8a9e-343024d9fff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for SVM Non-Linear Classification:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9583333333333334\n",
            "Precision: 1.0\n",
            "Recall: 0.9583333333333334\n",
            "F1 Score: 0.9787234042553191\n",
            "Accuracy: 0.999820884828945\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9583333333333334\n",
            "Precision: 1.0\n",
            "Recall: 0.9583333333333334\n",
            "F1 Score: 0.9787234042553191\n",
            "Accuracy: 0.999820884828945\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9583333333333334\n",
            "Precision: 1.0\n",
            "Recall: 0.9583333333333334\n",
            "F1 Score: 0.9787234042553191\n",
            "Accuracy: 0.999820884828945\n",
            "\n",
            "Overall accuracy: 0.999820884828945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (RBF)\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTkeUKDEzg5D",
        "outputId": "393f475a-1bfe-483f-bc1f-46f1c6c1590c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 2:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.8888888888888888\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9990982867448152\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9995489400090213\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8\n",
            "Precision: 1.0\n",
            "Recall: 0.8\n",
            "F1 Score: 0.888888888888889\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 5:\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9777777777777779\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9998196573489629\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9999097880018042\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9998209489704566\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.96\n",
            "Precision: 1.0\n",
            "Recall: 0.96\n",
            "F1 Score: 0.9777777777777779\n",
            "Accuracy: 0.9998209489704566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "negIoHuXzmSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}