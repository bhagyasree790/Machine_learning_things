{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdJFIEqXslu3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/k-means_clustered_dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "g25wLOy7j03N",
        "outputId": "a4c0cc87-c137-4dcf-aaab-94b489c9d7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Access to electricity (% of population)  \\\n",
              "0  2000                                 4.446891   \n",
              "1  2001                                 9.294527   \n",
              "2  2002                                14.133616   \n",
              "3  2003                                18.971165   \n",
              "4  2004                                23.814182   \n",
              "\n",
              "   Agricultural land (% of land area)  \\\n",
              "0                           57.945817   \n",
              "1                           57.947350   \n",
              "2                           57.939684   \n",
              "3                           58.083805   \n",
              "4                           58.151266   \n",
              "\n",
              "   Annual freshwater withdrawals, total (% of internal resources)  \\\n",
              "0                                          43.015907                \n",
              "1                                          43.015907                \n",
              "2                                          43.015907                \n",
              "3                                          43.015907                \n",
              "4                                          43.015907                \n",
              "\n",
              "   Arable land (% of land area)  Forest area (% of land area)  \\\n",
              "0                     11.779587                      1.852782   \n",
              "1                     11.779587                      1.852782   \n",
              "2                     11.771921                      1.852782   \n",
              "3                     11.916042                      1.852782   \n",
              "4                     11.983503                      1.852782   \n",
              "\n",
              "   Electric power consumption (kWh per capita)  \\\n",
              "0                                  1586.591120   \n",
              "1                                  1587.375364   \n",
              "2                                  1649.718098   \n",
              "3                                  1738.666619   \n",
              "4                                  1841.168267   \n",
              "\n",
              "   Energy use (kg of oil equivalent per capita)  \\\n",
              "0                                    985.730004   \n",
              "1                                   1011.679617   \n",
              "2                                   1034.410867   \n",
              "3                                   1010.524231   \n",
              "4                                   1121.869767   \n",
              "\n",
              "   Renewable electricity output (% of total electricity output)  \\\n",
              "0                                          74.989094              \n",
              "1                                          72.811460              \n",
              "2                                          79.063971              \n",
              "3                                          70.249729              \n",
              "4                                          70.890841              \n",
              "\n",
              "   Renewable energy consumption (% of total final energy consumption)  \\\n",
              "0                                              44.99                    \n",
              "1                                              45.60                    \n",
              "2                                              37.83                    \n",
              "3                                              36.66                    \n",
              "4                                              44.24                    \n",
              "\n",
              "   Population growth (annual %)  GDP per capita (current US$)  \\\n",
              "0                      1.443803                    182.174037   \n",
              "1                      0.742517                    182.174037   \n",
              "2                      6.449321                    182.174037   \n",
              "3                      7.541019                    199.643228   \n",
              "4                      3.933178                    221.830531   \n",
              "\n",
              "   CO2 emissions (metric tons per capita)  Cluster  \n",
              "0                                0.055167        1  \n",
              "1                                0.055293        1  \n",
              "2                                0.066810        1  \n",
              "3                                0.073005        1  \n",
              "4                                0.054867        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1613af1-4c45-4e28-80f2-69c3466d037f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Access to electricity (% of population)</th>\n",
              "      <th>Agricultural land (% of land area)</th>\n",
              "      <th>Annual freshwater withdrawals, total (% of internal resources)</th>\n",
              "      <th>Arable land (% of land area)</th>\n",
              "      <th>Forest area (% of land area)</th>\n",
              "      <th>Electric power consumption (kWh per capita)</th>\n",
              "      <th>Energy use (kg of oil equivalent per capita)</th>\n",
              "      <th>Renewable electricity output (% of total electricity output)</th>\n",
              "      <th>Renewable energy consumption (% of total final energy consumption)</th>\n",
              "      <th>Population growth (annual %)</th>\n",
              "      <th>GDP per capita (current US$)</th>\n",
              "      <th>CO2 emissions (metric tons per capita)</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>4.446891</td>\n",
              "      <td>57.945817</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1586.591120</td>\n",
              "      <td>985.730004</td>\n",
              "      <td>74.989094</td>\n",
              "      <td>44.99</td>\n",
              "      <td>1.443803</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>9.294527</td>\n",
              "      <td>57.947350</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.779587</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1587.375364</td>\n",
              "      <td>1011.679617</td>\n",
              "      <td>72.811460</td>\n",
              "      <td>45.60</td>\n",
              "      <td>0.742517</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.055293</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>14.133616</td>\n",
              "      <td>57.939684</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.771921</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1649.718098</td>\n",
              "      <td>1034.410867</td>\n",
              "      <td>79.063971</td>\n",
              "      <td>37.83</td>\n",
              "      <td>6.449321</td>\n",
              "      <td>182.174037</td>\n",
              "      <td>0.066810</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>18.971165</td>\n",
              "      <td>58.083805</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.916042</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1738.666619</td>\n",
              "      <td>1010.524231</td>\n",
              "      <td>70.249729</td>\n",
              "      <td>36.66</td>\n",
              "      <td>7.541019</td>\n",
              "      <td>199.643228</td>\n",
              "      <td>0.073005</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>23.814182</td>\n",
              "      <td>58.151266</td>\n",
              "      <td>43.015907</td>\n",
              "      <td>11.983503</td>\n",
              "      <td>1.852782</td>\n",
              "      <td>1841.168267</td>\n",
              "      <td>1121.869767</td>\n",
              "      <td>70.890841</td>\n",
              "      <td>44.24</td>\n",
              "      <td>3.933178</td>\n",
              "      <td>221.830531</td>\n",
              "      <td>0.054867</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1613af1-4c45-4e28-80f2-69c3466d037f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1613af1-4c45-4e28-80f2-69c3466d037f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1613af1-4c45-4e28-80f2-69c3466d037f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b150949d-796c-4a4a-a1e1-c331a6524020\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b150949d-796c-4a4a-a1e1-c331a6524020')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b150949d-796c-4a4a-a1e1-c331a6524020 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5586,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2000,\n        \"max\": 2020,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2000,\n          2017,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Access to electricity (% of population)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.009307167116457,\n        \"min\": 0.796382964,\n        \"max\": 100.0,\n        \"num_unique_values\": 3517,\n        \"samples\": [\n          18.72191048,\n          99.64420319,\n          57.97229767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agricultural land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.08418270854103,\n        \"min\": 0.448717949,\n        \"max\": 85.48737287,\n        \"num_unique_values\": 4205,\n        \"samples\": [\n          38.38383838,\n          60.42062566,\n          39.54077135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Annual freshwater withdrawals, total (% of internal resources)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 550.832181089681,\n        \"min\": 0.02036036,\n        \"max\": 7750.0,\n        \"num_unique_values\": 2609,\n        \"samples\": [\n          0.985916515,\n          318.3845455,\n          5832.045455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Arable land (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.513691681893778,\n        \"min\": 0.043140638,\n        \"max\": 64.14688484,\n        \"num_unique_values\": 3804,\n        \"samples\": [\n          7.869067642,\n          44.19781931,\n          28.97936625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forest area (% of land area)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.913181689877433,\n        \"min\": 0.0,\n        \"max\": 98.33891026,\n        \"num_unique_values\": 4408,\n        \"samples\": [\n          33.70594801,\n          90.03712486,\n          25.05576326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Electric power consumption (kWh per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4325.196010328713,\n        \"min\": 22.48184434,\n        \"max\": 54799.17471,\n        \"num_unique_values\": 3644,\n        \"samples\": [\n          2658.418628118782,\n          206.2771632,\n          8174.408162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Energy use (kg of oil equivalent per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4760.337500642505,\n        \"min\": 9.579196003,\n        \"max\": 197209.00845990723,\n        \"num_unique_values\": 3807,\n        \"samples\": [\n          695.1348324,\n          565.3273918,\n          3205.328271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable electricity output (% of total electricity output)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.55740141599933,\n        \"min\": -2.76281104889535,\n        \"max\": 100.47239374276964,\n        \"num_unique_values\": 4436,\n        \"samples\": [\n          21.57118997,\n          99.89101477,\n          24.69010449387077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Renewable energy consumption (% of total final energy consumption)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.609065972127446,\n        \"min\": 0.0,\n        \"max\": 98.34,\n        \"num_unique_values\": 3997,\n        \"samples\": [\n          79.02,\n          21.19,\n          77.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population growth (annual %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4711193274065608,\n        \"min\": -6.852117676,\n        \"max\": 19.36042866,\n        \"num_unique_values\": 5523,\n        \"samples\": [\n          0.025087267,\n          -1.666382643,\n          0.76783354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP per capita (current US$)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22028.338711031764,\n        \"min\": 110.4608747,\n        \"max\": 204097.114,\n        \"num_unique_values\": 5351,\n        \"samples\": [\n          1492.377075,\n          4359.7924,\n          15595.6365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2 emissions (metric tons per capita)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.890510317312629,\n        \"min\": 0.0,\n        \"max\": 47.65696201,\n        \"num_unique_values\": 4359,\n        \"samples\": [\n          8.860393054,\n          0.215113481,\n          0.332610017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "T9lmPDwukJ7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Cluster'], axis=1)\n",
        "y = df['Cluster']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK_NGOtIj-MX",
        "outputId": "2f491f4a-396a-427f-86f6-10a90eb246c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4468, 13)\n",
            "X_test shape: (1118, 13)\n",
            "y_train shape: (4468,)\n",
            "y_test shape: (1118,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "c09KNOK2kkhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "twOkLIlvkZdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXWFafSekxmZ",
        "outputId": "84734eb1-eda5-491d-c023-d4f63e4866e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9915254237288136\n",
            "Sensitivity: 0.9977324263038548\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 0.9977324263038548\n",
            "F1 Score: 0.9977324263038548\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9977876106194691\n",
            "Sensitivity: 0.985981308411215\n",
            "Precision: 0.9906103286384976\n",
            "Recall: 0.985981308411215\n",
            "F1 Score: 0.9882903981264637\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990875912408759\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9565217391304348\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9777777777777777\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Overall accuracy: 0.9955277280858676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN with k-fold"
      ],
      "metadata": {
        "id": "T9LWume6lSXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"\\nFold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78I8rnZ-lQO_",
        "outputId": "c70fb73f-0b83-4af4-82df-7f472c73f9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9915254237288136\n",
            "Sensitivity: 0.9977324263038548\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 0.9977324263038548\n",
            "F1 Score: 0.9977324263038548\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9977876106194691\n",
            "Sensitivity: 0.985981308411215\n",
            "Precision: 0.9906103286384976\n",
            "Recall: 0.985981308411215\n",
            "F1 Score: 0.9882903981264637\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990875912408759\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9565217391304348\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9777777777777777\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9988558352402745\n",
            "Precision: 1.0\n",
            "Recall: 0.9988558352402745\n",
            "F1 Score: 0.9994275901545506\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9966996699669967\n",
            "Sensitivity: 0.9951923076923077\n",
            "Precision: 0.9857142857142858\n",
            "Recall: 0.9951923076923077\n",
            "F1 Score: 0.9904306220095694\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990757855822551\n",
            "Sensitivity: 0.9428571428571428\n",
            "Precision: 0.9705882352941176\n",
            "Recall: 0.9428571428571428\n",
            "F1 Score: 0.9565217391304348\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.99581589958159\n",
            "Sensitivity: 0.9988610478359908\n",
            "Precision: 0.9988610478359908\n",
            "Recall: 0.9988610478359908\n",
            "F1 Score: 0.9988610478359908\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9978094194961665\n",
            "Sensitivity: 0.9950980392156863\n",
            "Precision: 0.9902439024390244\n",
            "Recall: 0.9950980392156863\n",
            "F1 Score: 0.9926650366748165\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9714285714285714\n",
            "F1 Score: 0.9855072463768115\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.992\n",
            "Sensitivity: 0.9988465974625144\n",
            "Precision: 0.9976958525345622\n",
            "Recall: 0.9988465974625144\n",
            "F1 Score: 0.9982708933717578\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9988839285714286\n",
            "Sensitivity: 0.9864253393665159\n",
            "Precision: 0.9954337899543378\n",
            "Recall: 0.9864253393665159\n",
            "F1 Score: 0.990909090909091\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990808823529411\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9666666666666667\n",
            "Recall: 1.0\n",
            "F1 Score: 0.983050847457627\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9955056179775281\n",
            "Precision: 1.0\n",
            "Recall: 0.9955056179775281\n",
            "F1 Score: 0.9977477477477478\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9946524064171123\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9732620320855615\n",
            "Recall: 1.0\n",
            "F1 Score: 0.986449864498645\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9777777777777777\n",
            "Precision: 1.0\n",
            "Recall: 0.9777777777777777\n",
            "F1 Score: 0.9887640449438202\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9958682646620808\n",
            "Sensitivity: 0.9979603049640327\n",
            "Precision: 0.9988578653348817\n",
            "Recall: 0.9979603049640327\n",
            "F1 Score: 0.9984079410827803\n",
            "Accuracy: 0.9962407291444789\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9971666070142348\n",
            "Sensitivity: 0.992539398937145\n",
            "Precision: 0.9870528677663414\n",
            "Recall: 0.992539398937145\n",
            "F1 Score: 0.9897490024437172\n",
            "Accuracy: 0.9962407291444789\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9994488518352144\n",
            "Sensitivity: 0.9784126984126983\n",
            "Precision: 0.9787553282182438\n",
            "Recall: 0.9784126984126983\n",
            "F1 Score: 0.9783243311372942\n",
            "Accuracy: 0.9962407291444789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree"
      ],
      "metadata": {
        "id": "yGFalNzClvrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': None, 'sensitivity': None, 'precision': None, 'recall': None, 'f1_score': None, 'accuracy': None} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiGtNbc9mI7t",
        "outputId": "fd32cdc5-3c13-492f-e293-0f520964b2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9943820224719101\n",
            "Precision: 1.0\n",
            "Recall: 0.9943820224719101\n",
            "F1 Score: 0.9971830985915493\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9946524064171123\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9732620320855615\n",
            "Recall: 1.0\n",
            "F1 Score: 0.986449864498645\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Overall accuracy: 0.9955237242614146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = dt.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjS-WeEelvBW",
        "outputId": "98ddeea7-0126-4ffa-c30c-acc1114e5143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9872881355932204\n",
            "Sensitivity: 0.9988662131519275\n",
            "Precision: 0.996606334841629\n",
            "Recall: 0.9988662131519275\n",
            "F1 Score: 0.9977349943374858\n",
            "Accuracy: 0.9946332737030411\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9988938053097345\n",
            "Sensitivity: 0.9766355140186916\n",
            "Precision: 0.9952380952380953\n",
            "Recall: 0.9766355140186916\n",
            "F1 Score: 0.9858490566037736\n",
            "Accuracy: 0.9946332737030411\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9981751824817519\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9166666666666666\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9565217391304348\n",
            "Accuracy: 0.9946332737030411\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977116704805492\n",
            "Precision: 1.0\n",
            "Recall: 0.9977116704805492\n",
            "F1 Score: 0.9988545246277205\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9966996699669967\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.985781990521327\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9928400954653938\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9714285714285714\n",
            "F1 Score: 0.9855072463768115\n",
            "Accuracy: 0.9973142345568488\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.976\n",
            "Sensitivity: 0.9988465974625144\n",
            "Precision: 0.9931192660550459\n",
            "Recall: 0.9988465974625144\n",
            "F1 Score: 0.9959746981023576\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9988839285714286\n",
            "Sensitivity: 0.9728506787330317\n",
            "Precision: 0.9953703703703703\n",
            "Recall: 0.9728506787330317\n",
            "F1 Score: 0.9839816933638443\n",
            "Accuracy: 0.9937332139659804\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9937332139659804\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9943820224719101\n",
            "Precision: 1.0\n",
            "Recall: 0.9943820224719101\n",
            "F1 Score: 0.9971830985915493\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9946524064171123\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9732620320855615\n",
            "Recall: 1.0\n",
            "F1 Score: 0.986449864498645\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9926576271186441\n",
            "Sensitivity: 0.9979613007133803\n",
            "Precision: 0.9979451201793349\n",
            "Recall: 0.9979613007133803\n",
            "F1 Score: 0.9979494631318225\n",
            "Accuracy: 0.9962408892974569\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9978259620530544\n",
            "Sensitivity: 0.9898972385503446\n",
            "Precision: 0.9899304976430707\n",
            "Recall: 0.9898972385503446\n",
            "F1 Score: 0.9898241419863314\n",
            "Accuracy: 0.9962408892974569\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9996350364963504\n",
            "Sensitivity: 0.9942857142857143\n",
            "Precision: 0.9833333333333332\n",
            "Recall: 0.9942857142857143\n",
            "F1 Score: 0.9884057971014493\n",
            "Accuracy: 0.9962408892974569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network"
      ],
      "metadata": {
        "id": "dKOa2UhGmfiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    scores[label]['specificity'] = specificity\n",
        "    scores[label]['sensitivity'] = sensitivity\n",
        "    scores[label]['precision'] = precision\n",
        "    scores[label]['recall'] = recall\n",
        "    scores[label]['f1_score'] = f1_score\n",
        "    scores[label]['accuracy'] = accuracy\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", scores[label]['specificity'])\n",
        "    print(\"Sensitivity:\", scores[label]['sensitivity'])\n",
        "    print(\"Precision:\", scores[label]['precision'])\n",
        "    print(\"Recall:\", scores[label]['recall'])\n",
        "    print(\"F1 Score:\", scores[label]['f1_score'])\n",
        "    print(\"Accuracy:\", scores[label]['accuracy'])\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgOwPKOMmD3Z",
        "outputId": "549ae992-8220-4384-e237-a12711c7f8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9741573033707865\n",
            "Precision: 1.0\n",
            "Recall: 0.9741573033707865\n",
            "F1 Score: 0.9869095048377916\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9732620320855615\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.8792270531400966\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9357326478149101\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9555555555555556\n",
            "Precision: 1.0\n",
            "Recall: 0.9555555555555556\n",
            "F1 Score: 0.9772727272727273\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Overall accuracy: 0.9776186213070726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Neural Network classifier\n",
        "nn = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nn.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-_Rgw56mt7q",
        "outputId": "8c31828e-0c48-4f17-a597-cfca0abbca74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9957627118644068\n",
            "Sensitivity: 0.9807256235827665\n",
            "Precision: 0.9988452655889145\n",
            "Recall: 0.9807256235827665\n",
            "F1 Score: 0.9897025171624715\n",
            "Accuracy: 0.9821109123434705\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9789823008849557\n",
            "Sensitivity: 0.9953271028037384\n",
            "Precision: 0.9181034482758621\n",
            "Recall: 0.9953271028037384\n",
            "F1 Score: 0.9551569506726457\n",
            "Accuracy: 0.9821109123434705\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9090909090909091\n",
            "Precision: 1.0\n",
            "Recall: 0.9090909090909091\n",
            "F1 Score: 0.9523809523809523\n",
            "Accuracy: 0.9821109123434705\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9917695473251029\n",
            "Sensitivity: 0.9965675057208238\n",
            "Precision: 0.997709049255441\n",
            "Recall: 0.9965675057208238\n",
            "F1 Score: 0.9971379507727534\n",
            "Accuracy: 0.97224709042077\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9966996699669967\n",
            "Sensitivity: 0.8653846153846154\n",
            "Precision: 0.9836065573770492\n",
            "Recall: 0.8653846153846154\n",
            "F1 Score: 0.9207161125319693\n",
            "Accuracy: 0.97224709042077\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9759704251386322\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5737704918032787\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7291666666666666\n",
            "Accuracy: 0.97224709042077\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9578587699316629\n",
            "Precision: 1.0\n",
            "Recall: 0.9578587699316629\n",
            "F1 Score: 0.97847585805701\n",
            "Accuracy: 0.9570277529095792\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9518072289156626\n",
            "Sensitivity: 0.9803921568627451\n",
            "Precision: 0.819672131147541\n",
            "Recall: 0.9803921568627451\n",
            "F1 Score: 0.8928571428571428\n",
            "Accuracy: 0.9570277529095792\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9963031423290203\n",
            "Sensitivity: 0.8\n",
            "Precision: 0.875\n",
            "Recall: 0.8\n",
            "F1 Score: 0.8358208955223881\n",
            "Accuracy: 0.9570277529095792\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.98\n",
            "Sensitivity: 0.9976931949250288\n",
            "Precision: 0.9942528735632183\n",
            "Recall: 0.9976931949250288\n",
            "F1 Score: 0.9959700633275763\n",
            "Accuracy: 0.991047448522829\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9977678571428571\n",
            "Sensitivity: 0.9638009049773756\n",
            "Precision: 0.9906976744186047\n",
            "Recall: 0.9638009049773756\n",
            "F1 Score: 0.9770642201834864\n",
            "Accuracy: 0.991047448522829\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9972426470588235\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.90625\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9508196721311475\n",
            "Accuracy: 0.991047448522829\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9741573033707865\n",
            "Precision: 1.0\n",
            "Recall: 0.9741573033707865\n",
            "F1 Score: 0.9869095048377916\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9732620320855615\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.8792270531400966\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9357326478149101\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9555555555555556\n",
            "Precision: 1.0\n",
            "Recall: 0.9555555555555556\n",
            "F1 Score: 0.9772727272727273\n",
            "Accuracy: 0.9776186213070726\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9935064518379019\n",
            "Sensitivity: 0.9814004795062138\n",
            "Precision: 0.9981614376815149\n",
            "Recall: 0.9814004795062138\n",
            "F1 Score: 0.9896391788315204\n",
            "Accuracy: 0.9760103651007442\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9797038177992068\n",
            "Sensitivity: 0.9609809560056949\n",
            "Precision: 0.9182613728718307\n",
            "Recall: 0.9609809560056949\n",
            "F1 Score: 0.9363054148120309\n",
            "Accuracy: 0.9760103651007442\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9939032429052951\n",
            "Sensitivity: 0.9329292929292929\n",
            "Precision: 0.8710040983606557\n",
            "Recall: 0.9329292929292929\n",
            "F1 Score: 0.8890921827947764\n",
            "Accuracy: 0.9760103651007442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "0N5Tt7AOnD5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "X2R59pA6m_pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier (GaussianNB for continuous features)\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the entire training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=nb.classes_)\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(nb.classes_):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7nccmnnOs5",
        "outputId": "30b53c83-66fe-4547-b327-1bd011ac646c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9832089552238806\n",
            "Sensitivity: 0.9555555555555556\n",
            "Precision: 0.7049180327868853\n",
            "Recall: 0.9555555555555556\n",
            "F1 Score: 0.8113207547169811\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9911894273127754\n",
            "Sensitivity: 0.9191011235955057\n",
            "Precision: 0.9975609756097561\n",
            "Recall: 0.9191011235955057\n",
            "F1 Score: 0.9567251461988303\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9208556149732621\n",
            "Sensitivity: 0.8901098901098901\n",
            "Precision: 0.6864406779661016\n",
            "Recall: 0.8901098901098901\n",
            "F1 Score: 0.7751196172248803\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Overall accuracy: 0.9158460161145927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    nb.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = nb.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufbCiD1vnc_w",
        "outputId": "514e17f5-52c1-40d1-f186-758ccc6b2395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9036281179138322\n",
            "Precision: 1.0\n",
            "Recall: 0.9036281179138322\n",
            "F1 Score: 0.9493746277546158\n",
            "Accuracy: 0.9087656529516994\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9059734513274337\n",
            "Sensitivity: 0.9205607476635514\n",
            "Precision: 0.6985815602836879\n",
            "Recall: 0.9205607476635514\n",
            "F1 Score: 0.7943548387096774\n",
            "Accuracy: 0.9087656529516994\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9844890510948905\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.5641025641025641\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7213114754098361\n",
            "Accuracy: 0.9087656529516994\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.8947368421052632\n",
            "Precision: 1.0\n",
            "Recall: 0.8947368421052632\n",
            "F1 Score: 0.9444444444444444\n",
            "Accuracy: 0.88272157564906\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.8965896589658966\n",
            "Sensitivity: 0.8221153846153846\n",
            "Precision: 0.6452830188679245\n",
            "Recall: 0.8221153846153846\n",
            "F1 Score: 0.7230443974630021\n",
            "Accuracy: 0.88272157564906\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9658040665434381\n",
            "Sensitivity: 0.9428571428571428\n",
            "Precision: 0.4714285714285714\n",
            "Recall: 0.9428571428571428\n",
            "F1 Score: 0.6285714285714287\n",
            "Accuracy: 0.88272157564906\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9066059225512528\n",
            "Precision: 1.0\n",
            "Recall: 0.9066059225512528\n",
            "F1 Score: 0.951015531660693\n",
            "Accuracy: 0.9015219337511191\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9079956188389924\n",
            "Sensitivity: 0.8725490196078431\n",
            "Precision: 0.6793893129770993\n",
            "Recall: 0.8725490196078431\n",
            "F1 Score: 0.7639484978540771\n",
            "Accuracy: 0.9015219337511191\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9759704251386322\n",
            "Sensitivity: 0.9428571428571428\n",
            "Precision: 0.559322033898305\n",
            "Recall: 0.9428571428571428\n",
            "F1 Score: 0.7021276595744681\n",
            "Accuracy: 0.9015219337511191\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.996\n",
            "Sensitivity: 0.9181084198385236\n",
            "Precision: 0.998745294855709\n",
            "Recall: 0.9181084198385236\n",
            "F1 Score: 0.9567307692307693\n",
            "Accuracy: 0.9212175470008953\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9207589285714286\n",
            "Sensitivity: 0.9230769230769231\n",
            "Precision: 0.7418181818181818\n",
            "Recall: 0.9230769230769231\n",
            "F1 Score: 0.8225806451612903\n",
            "Accuracy: 0.9212175470008953\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9852941176470589\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.6444444444444445\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7837837837837839\n",
            "Accuracy: 0.9212175470008953\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9911894273127754\n",
            "Sensitivity: 0.9191011235955057\n",
            "Precision: 0.9975609756097561\n",
            "Recall: 0.9191011235955057\n",
            "F1 Score: 0.9567251461988303\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9208556149732621\n",
            "Sensitivity: 0.8901098901098901\n",
            "Precision: 0.6864406779661016\n",
            "Recall: 0.8901098901098901\n",
            "F1 Score: 0.7751196172248803\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9832089552238806\n",
            "Sensitivity: 0.9555555555555556\n",
            "Precision: 0.7049180327868853\n",
            "Recall: 0.9555555555555556\n",
            "F1 Score: 0.8113207547169811\n",
            "Accuracy: 0.9158460161145927\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9974378854625551\n",
            "Sensitivity: 0.9084360852008755\n",
            "Precision: 0.9992612540930932\n",
            "Recall: 0.9084360852008755\n",
            "F1 Score: 0.9516581038578705\n",
            "Accuracy: 0.9060145450934733\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9104346545354026\n",
            "Sensitivity: 0.8856823930147186\n",
            "Precision: 0.690302550382599\n",
            "Recall: 0.8856823930147186\n",
            "F1 Score: 0.7758095992825854\n",
            "Accuracy: 0.9060145450934733\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.97895332312958\n",
            "Sensitivity: 0.9682539682539681\n",
            "Precision: 0.588843129332154\n",
            "Recall: 0.9682539682539681\n",
            "F1 Score: 0.7294230204112996\n",
            "Accuracy: 0.9060145450934733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Linear"
      ],
      "metadata": {
        "id": "HplPCndAn6dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "pdgFqJfanpYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM linear classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Generate confusion matrix\n",
        "labels = y.unique()\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "# Print evaluation metrics\n",
        "# Iterate over indices and labels simultaneously\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N6DVL_En-v8",
        "outputId": "b26cbd11-2f6c-49ef-c90d-ee2efd0363d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977528089887641\n",
            "Precision: 1.0\n",
            "Recall: 0.9977528089887641\n",
            "F1 Score: 0.998875140607424\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9967914438502674\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9837837837837838\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9918256130790191\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9777777777777777\n",
            "Precision: 1.0\n",
            "Recall: 0.9777777777777777\n",
            "F1 Score: 0.9887640449438202\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Overall accuracy: 0.9973142345568488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a linear kernel\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqne1p-iodEE",
        "outputId": "0c12b04f-309c-4872-e8de-ab32ede6ee45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977324263038548\n",
            "Precision: 1.0\n",
            "Recall: 0.9977324263038548\n",
            "F1 Score: 0.9988649262202043\n",
            "Accuracy: 0.9973166368515206\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9977876106194691\n",
            "Sensitivity: 0.9953271028037384\n",
            "Precision: 0.9906976744186047\n",
            "Recall: 0.9953271028037384\n",
            "F1 Score: 0.9930069930069931\n",
            "Accuracy: 0.9973166368515206\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990875912408759\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9565217391304348\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9777777777777777\n",
            "Accuracy: 0.9973166368515206\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 1.0\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9989047097480832\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9951219512195122\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9975550122249389\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9714285714285714\n",
            "F1 Score: 0.9855072463768115\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.988\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.996551724137931\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9982728842832469\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9864253393665159\n",
            "Precision: 1.0\n",
            "Recall: 0.9864253393665159\n",
            "F1 Score: 0.9931662870159453\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9973142345568488\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9977528089887641\n",
            "Precision: 1.0\n",
            "Recall: 0.9977528089887641\n",
            "F1 Score: 0.998875140607424\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9967914438502674\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9837837837837838\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9918256130790191\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9777777777777777\n",
            "Precision: 1.0\n",
            "Recall: 0.9777777777777777\n",
            "F1 Score: 0.9887640449438202\n",
            "Accuracy: 0.9973142345568488\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9975999999999999\n",
            "Sensitivity: 0.9990970470585238\n",
            "Precision: 0.9993103448275862\n",
            "Recall: 0.9990970470585238\n",
            "F1 Score: 0.9992025902221752\n",
            "Accuracy: 0.9982099701635002\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.998696752843564\n",
            "Sensitivity: 0.9963504884340508\n",
            "Precision: 0.99392068188438\n",
            "Recall: 0.9963504884340508\n",
            "F1 Score: 0.9951107810653792\n",
            "Accuracy: 0.9982099701635002\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9998175182481752\n",
            "Sensitivity: 0.9898412698412699\n",
            "Precision: 0.9913043478260869\n",
            "Recall: 0.9898412698412699\n",
            "F1 Score: 0.9904098138196819\n",
            "Accuracy: 0.9982099701635002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Non-Linear"
      ],
      "metadata": {
        "id": "rv5tr_ckoxdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (e.g., 'rbf')\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# Fit the classifier on the entire dataset\n",
        "svm.fit(X, y)\n",
        "\n",
        "# Predict on the same dataset\n",
        "y_pred = svm.predict(X)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y, y_pred, output_dict=True)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': 0, 'sensitivity': 0, 'precision': 0, 'recall': 0, 'f1_score': 0, 'accuracy': 0} for label in labels}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y, y_pred, labels=labels)\n",
        "\n",
        "# Extract evaluation metrics for each label\n",
        "for idx, label in enumerate(labels):\n",
        "    tp = cm[idx, idx]  # True Positive\n",
        "    fn = cm[idx, :].sum() - tp  # False Negative\n",
        "    fp = cm[:, idx].sum() - tp  # False Positive\n",
        "    tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    precision = report[str(label)]['precision']\n",
        "    recall = report[str(label)]['recall']\n",
        "    f1_score = report[str(label)]['f1-score']\n",
        "    accuracy = report['accuracy']\n",
        "\n",
        "\n",
        "# Print evaluation metrics for each label\n",
        "print(\"Evaluation Metrics for SVM Non-Linear Classification:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Scores:\")\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"Sensitivity:\", sensitivity)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1_score)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Summarize results\n",
        "print(\"\\nOverall accuracy:\", report['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOAdwHA-o9yM",
        "outputId": "d28d2ad3-5145-4f79-b5b3-612a0b1404e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for SVM Non-Linear Classification:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9998154981549815\n",
            "Sensitivity: 0.9879518072289156\n",
            "Precision: 0.9939393939393939\n",
            "Recall: 0.9879518072289156\n",
            "F1 Score: 0.9909365558912386\n",
            "Accuracy: 0.9978517722878625\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9998154981549815\n",
            "Sensitivity: 0.9879518072289156\n",
            "Precision: 0.9939393939393939\n",
            "Recall: 0.9879518072289156\n",
            "F1 Score: 0.9909365558912386\n",
            "Accuracy: 0.9978517722878625\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9998154981549815\n",
            "Sensitivity: 0.9879518072289156\n",
            "Precision: 0.9939393939393939\n",
            "Recall: 0.9879518072289156\n",
            "F1 Score: 0.9909365558912386\n",
            "Accuracy: 0.9978517722878625\n",
            "\n",
            "Overall accuracy: 0.9978517722878625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM classifier with a non-linear kernel (RBF)\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get unique labels from the 'Outcome' column\n",
        "labels = y.unique()\n",
        "\n",
        "# Dictionary to store evaluation metrics\n",
        "avg_scores = {label: {'specificity': [], 'sensitivity': [], 'precision': [], 'recall': [], 'f1_score': [], 'accuracy': []} for label in labels}\n",
        "\n",
        "# Perform KFold cross-validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "\n",
        "    # Extract evaluation metrics for each label\n",
        "    for idx, label in enumerate(labels):\n",
        "        tp = cm[idx, idx]  # True Positive\n",
        "        fn = cm[idx, :].sum() - tp  # False Negative\n",
        "        fp = cm[:, idx].sum() - tp  # False Positive\n",
        "        tn = cm.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = report[str(label)]['precision']\n",
        "        recall = report[str(label)]['recall']\n",
        "        f1_score = report[str(label)]['f1-score']\n",
        "        accuracy = report['accuracy']\n",
        "\n",
        "        avg_scores[label]['specificity'].append(specificity)\n",
        "        avg_scores[label]['sensitivity'].append(sensitivity)\n",
        "        avg_scores[label]['precision'].append(precision)\n",
        "        avg_scores[label]['recall'].append(recall)\n",
        "        avg_scores[label]['f1_score'].append(f1_score)\n",
        "        avg_scores[label]['accuracy'].append(accuracy)\n",
        "\n",
        "    # Print evaluation metrics for each label after each iteration\n",
        "    print(f\"Fold {i+1}:\")\n",
        "    for label in labels:\n",
        "        print(f\"\\nLabel '{label}' Scores:\")\n",
        "        print(\"Specificity:\", avg_scores[label]['specificity'][-1])\n",
        "        print(\"Sensitivity:\", avg_scores[label]['sensitivity'][-1])\n",
        "        print(\"Precision:\", avg_scores[label]['precision'][-1])\n",
        "        print(\"Recall:\", avg_scores[label]['recall'][-1])\n",
        "        print(\"F1 Score:\", avg_scores[label]['f1_score'][-1])\n",
        "        print(\"Accuracy:\", avg_scores[label]['accuracy'][-1])\n",
        "\n",
        "# Summarize results across all folds\n",
        "print(\"\\nAverage scores across all folds:\")\n",
        "for label in labels:\n",
        "    print(f\"\\nLabel '{label}' Average Scores:\")\n",
        "    print(\"Specificity:\", sum(avg_scores[label]['specificity']) / len(avg_scores[label]['specificity']))\n",
        "    print(\"Sensitivity:\", sum(avg_scores[label]['sensitivity']) / len(avg_scores[label]['sensitivity']))\n",
        "    print(\"Precision:\", sum(avg_scores[label]['precision']) / len(avg_scores[label]['precision']))\n",
        "    print(\"Recall:\", sum(avg_scores[label]['recall']) / len(avg_scores[label]['recall']))\n",
        "    print(\"F1 Score:\", sum(avg_scores[label]['f1_score']) / len(avg_scores[label]['f1_score']))\n",
        "    print(\"Accuracy:\", sum(avg_scores[label]['accuracy']) / len(avg_scores[label]['accuracy']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze__-lBmouwS",
        "outputId": "28415d5a-6ed6-4e37-82e1-1ce1738fedcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9915254237288136\n",
            "Sensitivity: 0.9977324263038548\n",
            "Precision: 0.9977324263038548\n",
            "Recall: 0.9977324263038548\n",
            "F1 Score: 0.9977324263038548\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9977876106194691\n",
            "Sensitivity: 0.985981308411215\n",
            "Precision: 0.9906103286384976\n",
            "Recall: 0.985981308411215\n",
            "F1 Score: 0.9882903981264637\n",
            "Accuracy: 0.9955277280858676\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 0.9990875912408759\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9565217391304348\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9777777777777777\n",
            "Accuracy: 0.9955277280858676\n",
            "Fold 2:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9988998899889989\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9952153110047847\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9976019184652278\n",
            "Accuracy: 0.999104744852283\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9714285714285714\n",
            "F1 Score: 0.9855072463768115\n",
            "Accuracy: 0.999104744852283\n",
            "Fold 3:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.99581589958159\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9988623435722411\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9994308480364257\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9989047097480832\n",
            "Sensitivity: 0.9950980392156863\n",
            "Precision: 0.9950980392156863\n",
            "Recall: 0.9950980392156863\n",
            "F1 Score: 0.9950980392156863\n",
            "Accuracy: 0.9982094897045658\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.9714285714285714\n",
            "F1 Score: 0.9855072463768115\n",
            "Accuracy: 0.9982094897045658\n",
            "Fold 4:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.984\n",
            "Sensitivity: 1.0\n",
            "Precision: 0.9954075774971297\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9976985040276178\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9819004524886877\n",
            "Precision: 1.0\n",
            "Recall: 0.9819004524886877\n",
            "F1 Score: 0.9908675799086757\n",
            "Accuracy: 0.9964189794091316\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Accuracy: 0.9964189794091316\n",
            "Fold 5:\n",
            "\n",
            "Label '1' Scores:\n",
            "Specificity: 0.9955947136563876\n",
            "Sensitivity: 0.996629213483146\n",
            "Precision: 0.9988738738738738\n",
            "Recall: 0.996629213483146\n",
            "F1 Score: 0.9977502812148482\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '2' Scores:\n",
            "Specificity: 0.9957219251336898\n",
            "Sensitivity: 0.9945054945054945\n",
            "Precision: 0.9783783783783784\n",
            "Recall: 0.9945054945054945\n",
            "F1 Score: 0.9863760217983651\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Label '0' Scores:\n",
            "Specificity: 1.0\n",
            "Sensitivity: 0.9777777777777777\n",
            "Precision: 1.0\n",
            "Recall: 0.9777777777777777\n",
            "F1 Score: 0.9887640449438202\n",
            "Accuracy: 0.9955237242614146\n",
            "\n",
            "Average scores across all folds:\n",
            "\n",
            "Label '1' Average Scores:\n",
            "Specificity: 0.9933872073933582\n",
            "Sensitivity: 0.9988723279574001\n",
            "Precision: 0.99817524424942\n",
            "Recall: 0.9988723279574001\n",
            "F1 Score: 0.9985224119165494\n",
            "Accuracy: 0.9969569332626526\n",
            "\n",
            "Label '2' Average Scores:\n",
            "Specificity: 0.9982628270980483\n",
            "Sensitivity: 0.9914970589242167\n",
            "Precision: 0.9918604114474695\n",
            "Recall: 0.9914970589242167\n",
            "F1 Score: 0.9916467915028836\n",
            "Accuracy: 0.9969569332626526\n",
            "\n",
            "Label '0' Average Scores:\n",
            "Specificity: 0.9998175182481752\n",
            "Sensitivity: 0.9841269841269842\n",
            "Precision: 0.9913043478260869\n",
            "Recall: 0.9841269841269842\n",
            "F1 Score: 0.9875112630950442\n",
            "Accuracy: 0.9969569332626526\n"
          ]
        }
      ]
    }
  ]
}